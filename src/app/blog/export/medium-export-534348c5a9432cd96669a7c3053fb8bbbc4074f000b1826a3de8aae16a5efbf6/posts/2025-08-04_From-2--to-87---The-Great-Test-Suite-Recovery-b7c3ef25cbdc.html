<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>From 2% to 87%: The Great Test Suite Recovery</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">From 2% to 87%: The Great Test Suite Recovery</h1>
</header>
<section data-field="subtitle" class="p-summary">
July 13
</section>
<section data-field="body" class="e-content">
<section name="44d4" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="23aa" id="23aa" class="graf graf--h3 graf--leading graf--title">From 2% to 87%: The Great Test Suite Recovery</h3><figure name="26f4" id="26f4" class="graf graf--figure graf--startsWithDoubleQuote graf-after--h3"><img class="graf-image" data-image-id="1*DX6049KTiHXt5TFDdbmeFg.png" data-width="1536" data-height="1024" data-is-featured="true" alt="A robot doctor and a human doctor watch over a patient who has made a full recovery." src="https://cdn-images-1.medium.com/max/800/1*DX6049KTiHXt5TFDdbmeFg.png"><figcaption class="imageCaption">“You’re going home!”</figcaption></figure><p name="7b90" id="7b90" class="graf graf--p graf-after--figure"><em class="markup--em markup--p-em">July 13</em></p><p name="c843" id="c843" class="graf graf--p graf--hasDropCapModel graf--hasDropCap graf-after--p"><span class="graf-dropCap">T</span>here’s a special kind of despair that comes with seeing your test suite report 144 failures and 19 errors out of 204 total tests. A 2% pass rate isn’t just broken — it’s catastrophically broken. It’s the kind of number that makes you question whether you should just delete everything and start over.</p><p name="41c9" id="41c9" class="graf graf--p graf-after--p">The day I wrote this, we climbed out of that hole, ending the day at 87% pass rate (177/204 tests passing). The journey from software disaster to mostly-working system taught me more about test infrastructure than three years of “testing best practices” blog posts.</p><h3 name="8415" id="8415" class="graf graf--h3 graf-after--p">The foundation: pre-commit hooks</h3><p name="7789" id="7789" class="graf graf--p graf-after--h3">The recovery actually started three days earlier with something mundane: setting up pre-commit hooks. I had been griping about needing to remember to update documentation every time we changed the code and my colleague at Kind, lead engineer Grace Xu, told me about the concept of pre-commit hooks.</p><p name="39a0" id="39a0" class="graf graf--p graf-after--p">Yes, I have worked in technology all my life and am still learning quotidian programming concepts daily.</p><p name="191d" id="191d" class="graf graf--p graf-after--p">I asked Claude to set some up and it configured black, flake8, isort, and other code quality tools to run automatically on every commit. It also reminds us to update documentation based on which files we changed.</p><p name="acee" id="acee" class="graf graf--p graf-after--p">This seemed like procrastination at the time — why format code when core functionality is broken? But it turned out to be essential. When you’re fixing 144 test failures, you need every bit of consistency and clarity you can get. Code formatting issues become cognitive overhead you can’t afford.</p><p name="6dc3" id="6dc3" class="graf graf--p graf-after--p">(At least that’s what I told myself. It is also possible I was being a digital magpie and just grabbing and absorbing every shiny new idea into my process.)</p><p name="d94e" id="d94e" class="graf graf--p graf-after--p">The pre-commit setup also revealed something important: we had 318 files that needed formatting fixes. That’s not a small project — that’s a sign of technical debt accumulation that was making everything harder to understand and debug.</p><h3 name="abcb" id="abcb" class="graf graf--h3 graf-after--p">The horror of 144 failures</h3><p name="2e37" id="2e37" class="graf graf--p graf-after--h3">Sunday morning, July 13. Fresh coffee, good intentions, and a test command that delivered soul-crushing results:</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="diff" name="fd18" id="fd18" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-comment">======================== 144 failed, 37 passed, 21 skipped, 19 errors ========================</span></span></pre><p name="724c" id="724c" class="graf graf--p graf-after--pre">Two percent. The kind of failure rate that suggests fundamental infrastructure problems, not minor bugs.</p><p name="02f5" id="02f5" class="graf graf--p graf-after--p">The failures fell into categories that told a story:</p><ul class="postList"><li name="b7a4" id="b7a4" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">AsyncSession leaks</strong> — Database sessions not being closed properly</li><li name="8fff" id="8fff" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Missing pytest-asyncio configuration</strong> — Async tests failing because pytest couldn’t run them</li><li name="d3c0" id="d3c0" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Fixture drift</strong> — Tests expecting fixtures that no longer existed</li><li name="e469" id="e469" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Contract violations</strong> — Components expecting interfaces that had changed</li><li name="1aa1" id="1aa1" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Float precision errors</strong> — Tests comparing floats with exact equality</li></ul><p name="23e6" id="23e6" class="graf graf--p graf-after--li">Each category represented weeks of accumulated technical debt coming due all at once.</p><h3 name="5b84" id="5b84" class="graf graf--h3 graf-after--p">The systematic triage approach</h3><p name="1749" id="1749" class="graf graf--p graf-after--h3">Rather than randomly fixing tests, we took a systematic approach:</p><h4 name="4e80" id="4e80" class="graf graf--h4 graf-after--p">Phase 1: Infrastructure fixes (the foundation)</h4><p name="b1e2" id="b1e2" class="graf graf--p graf-after--h4"><strong class="markup--strong markup--p-strong">The async session leak discovery</strong>: The most critical issue was database sessions not being closed properly in the query intent handler. This was causing cascading failures as tests shared database state.</p><p name="0486" id="0486" class="graf graf--p graf-after--p">The fix was surprisingly simple — add proper session management to <code class="markup--code markup--p-code">main.py</code>:</p><p name="3cb6" id="3cb6" class="graf graf--p graf-after--p">python</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="bash" name="d85d" id="d85d" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-comment"># Before: session leaked across requests</span><br /><br /><span class="hljs-comment"># After: proper async session lifecycle management</span></span></pre><p name="e7fe" id="e7fe" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">pytest-asyncio configuration</strong>: Half the test failures were because pytest couldn’t run async tests. Adding <code class="markup--code markup--p-code">pytest-asyncio</code> to requirements and configuring it properly eliminated 20+ failures immediately.</p><p name="e573" id="e573" class="graf graf--p graf-after--p">Where have I heard this one before? Ay-sink-ee-oooooh!</p><h4 name="eff3" id="eff3" class="graf graf--h4 graf-after--p">Phase 2: Fixture rehabilitation</h4><p name="7b1c" id="7b1c" class="graf graf--p graf-after--h4"><strong class="markup--strong markup--p-strong">Missing db_session fixture</strong>: Nine tests were failing because they expected an async database session fixture that didn’t exist. Creating the fixture in <code class="markup--code markup--p-code">conftest.py</code> unblocked an entire category of repository tests. I still don’t understand why my bots write tests and either don’t create the fixtures for the tests (and then act surprised when they fail) or create them and then “clean them up,” like some overclocked housekeeper.</p><p name="f8bf" id="f8bf" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Orchestration engine test refactoring</strong>: Tests were using mock domain models instead of real ones, causing contract mismatches. Updating them to use actual domain objects fixed another cluster of failures. Beware of test mocks! They are needed when you are testing workflows that are not fully built yet, but if they linger beyond when they are needed, they will trip you up.</p><h4 name="3491" id="3491" class="graf graf--h4 graf-after--p">Phase 3: Contract alignment</h4><p name="9d00" id="9d00" class="graf graf--p graf-after--h4"><strong class="markup--strong markup--p-strong">Enum case drift</strong>: Intent classification tests were failing because they expected different enum cases than the implementation was using. The kind of drift that happens when you’re moving fast and not running tests regularly. (It also seems to happen a lot because either these bots get sloppy or they are mixing up knowledge from programming languages with different conventions.)</p><p name="3911" id="3911" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Repository interface changes</strong>: Some tests expected connection pools while others expected sessions. The infrastructure changes we’d made for better async support had shifted interfaces without updating tests.</p><h3 name="2e0b" id="2e0b" class="graf graf--h3 graf-after--p">The psychological challenge</h3><p name="4389" id="4389" class="graf graf--p graf-after--h3">The hardest part wasn’t the technical fixes — it was maintaining the belief that the situation was recoverable. When you see 144 failures, the rational response is panic. When you fix 10 and still have 134 remaining, it’s easy to conclude you’re making no progress.</p><p name="d56b" id="d56b" class="graf graf--p graf-after--p">The breakthrough came when we started categorizing failures instead of just counting them. Once we could see that most failures were infrastructure issues rather than logic problems, the path forward became clearer.</p><h3 name="42ca" id="42ca" class="graf graf--h3 graf-after--p">The momentum shift</h3><p name="a816" id="a816" class="graf graf--p graf-after--h3">Around hour 4 of the recovery session, something shifted. The fixes started cascading. Resolving the async session leak eliminated 15 failures. Configuring pytest-asyncio properly fixed another 20. Adding the missing fixture unblocked 9 more.</p><p name="591d" id="591d" class="graf graf--p graf-after--p">Suddenly we weren’t fighting individual test failures — we were addressing systemic issues that affected multiple test categories. The pass rate went from 2% to 30% to 60% to 87% as each infrastructure fix unlocked multiple working tests.</p><h3 name="a868" id="a868" class="graf graf--h3 graf-after--p">What was still broken (and why that was OK)</h3><p name="8e4f" id="8e4f" class="graf graf--p graf-after--h3">The remaining 13% of test failures fall into categories that represent real work, not just infrastructure debt:</p><p name="9861" id="9861" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">FileRepository pool vs session architecture</strong>: Tests expect connection pools but the implementation now uses sessions. This represents an architectural decision that needs to be resolved, not just a bug to fix.</p><p name="11f5" id="11f5" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">API integration contract drift</strong>: Some query service tests are failing because the interfaces have evolved during development. These failures are telling us about API design decisions we need to make.</p><p name="393d" id="393d" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Logic assertion mismatches</strong>: Tests expecting specific float values or exact string matches that need to be updated for current implementation behavior.</p><p name="1a1b" id="1a1b" class="graf graf--p graf-after--p">These aren’t blocking failures — they’re indicators of technical decisions that need conscious resolution.</p><h3 name="61fe" id="61fe" class="graf graf--h3 graf-after--p">The infrastructure lessons</h3><p name="8c9f" id="8c9f" class="graf graf--p graf-after--h3">The recovery taught us several important principles about test infrastructure:</p><p name="512a" id="512a" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Async testing requires specific setup.</strong> pytest-asyncio isn’t optional when you’re building async systems — it’s foundational infrastructure that needs to be configured correctly from the start.</p><p name="4332" id="4332" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Database session management is critical.</strong> Session leaks don’t just affect performance — they make tests unpredictable and unreliable. Proper session lifecycle management is essential for test stability.</p><p name="522d" id="522d" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Formatting consistency reduces cognitive load.</strong> When you’re debugging complex failures, code formatting issues become mental overhead you can’t afford. Automated formatting is productivity infrastructure.</p><p name="5c7b" id="5c7b" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Systematic triage beats random fixing.</strong> Categorizing failures by root cause reveals the high-leverage fixes that unblock multiple tests at once.</p><h3 name="9323" id="9323" class="graf graf--h3 graf-after--p">The AI assistance reality</h3><p name="ccfc" id="ccfc" class="graf graf--p graf-after--h3">Cursor Assistant was invaluable for systematic analysis and fixture creation. But the recovery process highlighted something important: AI is excellent at executing solutions but human judgment is essential for prioritization.</p><p name="f5be" id="f5be" class="graf graf--p graf-after--p">When facing 144 failures, AI wants to fix them all in parallel. This can lead to a monomaniacal bug hunt based on guesswork that easily ends up down infinite rabbit holes.</p><p name="bdcc" id="bdcc" class="graf graf--p graf-after--p">Human insight recognizes that fixing async session management will eliminate 20 failures, while fixing individual assertion errors will eliminate one failure each.</p><p name="42e1" id="42e1" class="graf graf--p graf-after--p">The most effective pattern: human diagnoses systemic issues, AI executes systematic fixes.</p><h3 name="7850" id="7850" class="graf graf--h3 graf-after--p">The unexpected benefit</h3><p name="3655" id="3655" class="graf graf--p graf-after--h3">The test suite recovery revealed something we hadn’t appreciated: our architecture is actually quite solid. The failures were mostly infrastructure and configuration issues, not fundamental design problems.</p><p name="ee27" id="ee27" class="graf graf--p graf-after--p">The domain models are working correctly. The repository pattern is sound. The orchestration engine is reliable. The intent classification is accurate. The components we built with careful design are holding up under scrutiny.</p><p name="b9a6" id="b9a6" class="graf graf--p graf-after--p">That’s… actually pretty encouraging.</p><h3 name="9c18" id="9c18" class="graf graf--h3 graf-after--p">Looking forward</h3><p name="3576" id="3576" class="graf graf--p graf-after--h3">87% pass rate isn’t perfect, but it’s functional. (Spoiler: It will get better.)</p><p name="3726" id="3726" class="graf graf--p graf-after--p">The remaining failures represent conscious decisions to make rather than accumulated debt to fix. The test infrastructure is now solid enough to support ongoing development without constant firefighting.</p><p name="8945" id="8945" class="graf graf--p graf-after--p">More importantly, we’ve established a pattern for handling technical debt systematically rather than reactively. When the next batch of tests starts failing (and they will), we have a process for recovery that doesn’t involve panic and random fixes.</p><p name="7e37" id="7e37" class="graf graf--p graf-after--p graf--trailing">The great test suite recovery is complete. Now we can get back to building features instead of fighting infrastructure.</p></div></div></section><section name="6a1a" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="b7fb" id="b7fb" class="graf graf--p graf--leading"><em class="markup--em markup--p-em">Next in Building Piper Morgan: How we taught the system to speak human (and why “investigate_crash” needed to become “investigate a crash”)</em></p><p name="aca2" id="aca2" class="graf graf--p graf-after--p graf--trailing"><em class="markup--em markup--p-em">Have you ever stared at a seemingly hopeless situation and then realized that with a few fixes you could easily be back in business? I can relate!</em></p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@mediajunkie" class="p-author h-card">christian crumlish</a> on <a href="https://medium.com/p/b7c3ef25cbdc"><time class="dt-published" datetime="2025-08-04T13:59:01.673Z">August 4, 2025</time></a>.</p><p><a href="https://medium.com/@mediajunkie/from-2-to-87-the-great-test-suite-recovery-b7c3ef25cbdc" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on October 9, 2025.</p></footer></article></body></html>