<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Persistence of Memory: AI Can’t Learn without It</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Persistence of Memory: AI Can’t Learn without It</h1>
</header>
<section data-field="subtitle" class="p-summary">
(End of) June 2, 2025
</section>
<section data-field="body" class="e-content">
<section name="9464" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="7025" id="7025" class="graf graf--h3 graf--leading graf--title">Persistence of Memory: AI Can’t Learn without It</h3><p name="e66a" id="e66a" class="graf graf--p graf-after--h3"><em class="markup--em markup--p-em">(End of) June 2, 2025</em></p><figure name="b2da" id="b2da" class="graf graf--figure graf--startsWithDoubleQuote graf-after--p"><img class="graf-image" data-image-id="1*96hPt022j7TfTimPFxe73g.png" data-width="1536" data-height="1024" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*96hPt022j7TfTimPFxe73g.png"><figcaption class="imageCaption">“I think I’m getting it”</figcaption></figure><p name="ea8f" id="ea8f" class="graf graf--p graf--hasDropCapModel graf--hasDropCap graf-after--figure"><span class="graf-dropCap">T</span>here’s a moment in every AI project when you realize the difference between intelligence and memory. Intelligence can solve problems. Memory can learn from solutions. Today’s story is about trying to give Piper Morgan the ability to remember — and discovering that persistence is more complicated than “just add a database.”</p><h3 name="7471" id="7471" class="graf graf--h3 graf-after--p">The persistence problem</h3><p name="3164" id="3164" class="graf graf--p graf-after--h3">As of June 2, every conversation with Piper Morgan started from scratch. The intent classifier could achieve 0.95 confidence on PM requests, and the orchestration engine could execute multi-step workflows with context passing. But ask about a similar request the next day? Complete amnesia.</p><p name="f2bb" id="f2bb" class="graf graf--p graf-after--p">This was like having a brilliant consultant who gets a concussion between every meeting. Helpful in the moment, useless for building on previous insights.</p><p name="e9d7" id="e9d7" class="graf graf--p graf-after--p">The obvious solution was persistence. The less obvious challenge was figuring out what to persist.</p><h3 name="a56b" id="a56b" class="graf graf--h3 graf-after--p">The first attempt: store everything</h3><p name="86d0" id="86d0" class="graf graf--p graf-after--h3">My initial instinct was to save workflow results. User asks for feature analysis, AI generates recommendations, database stores the output. Simple enough.</p><p name="0b81" id="0b81" class="graf graf--p graf-after--p">But this approach treats AI interactions like static documents instead of dynamic learning opportunities. You get a historical record, not accumulated wisdom.</p><p name="8859" id="8859" class="graf graf--p graf-after--p">My LLM advisor suggested we shifted focus from storing outputs to storing the reasoning process itself.</p><h3 name="a2df" id="a2df" class="graf graf--h3 graf-after--p">Database design: domain models drive schema</h3><p name="8e2b" id="8e2b" class="graf graf--p graf-after--h3">The earlier June 2 session had laid important groundwork here. Instead of generic “AI_interactions” tables, we modeled PM concepts as first-class database entities:</p><p name="d307" id="d307" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Products</strong> with features and stakeholders <br><strong class="markup--strong markup--p-strong">WorkItems</strong> that can map to any external system<br><strong class="markup--strong markup--p-strong">Workflows</strong> that capture the complete analysis process <br><strong class="markup--strong markup--p-strong">Events</strong> that track every decision and outcome</p><p name="0b38" id="0b38" class="graf graf--p graf-after--p">This isn’t just better data modeling — it’s teaching the database to think in PM concepts.</p><h3 name="9259" id="9259" class="graf graf--h3 graf-after--p">The repository pattern revelation</h3><p name="b17b" id="b17b" class="graf graf--p graf-after--h3">Rather than scattering database queries throughout the codebase, we implemented a repository pattern. Every domain concept gets its own repository with clean CRUD (Create, Read, Update, and Delete) operations.</p><p name="4224" id="4224" class="graf graf--p graf-after--p">This sounds like developer inside baseball, but it matters for AI memory. When the system needs to find “similar feature requests,” it’s querying ProductRepository.find_similar(), not writing raw SQL scattered across different services.</p><p name="e5a5" id="e5a5" class="graf graf--p graf-after--p">The abstraction means we can later add sophisticated similarity search without changing how the rest of the system requests data.</p><h3 name="0e9d" id="0e9d" class="graf graf--h3 graf-after--p">What we’re actually persisting</h3><p name="a450" id="a450" class="graf graf--p graf-after--h3">The current system captures:</p><ul class="postList"><li name="420e" id="420e" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Complete workflow executions</strong> with timing and context</li><li name="81b2" id="81b2" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">AI decision points</strong> including confidence levels and alternatives considered</li><li name="3b9f" id="3b9f" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">User interactions</strong> mapped to PM domain concepts</li><li name="de3b" id="de3b" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Cross-workflow relationships</strong> between related requests</li></ul><p name="70e3" id="70e3" class="graf graf--p graf-after--li">But here’s what we’re not capturing yet:</p><ul class="postList"><li name="1fc6" id="1fc6" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Outcome data</strong> (did the feature actually get built? how did it perform?)</li><li name="4925" id="4925" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">User feedback</strong> on AI recommendations (were they helpful? accurate?)</li><li name="9bef" id="9bef" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Pattern improvements</strong> (learning from what works vs what doesn’t)</li></ul><p name="9485" id="9485" class="graf graf--p graf-after--li">The foundation supports these capabilities, but we haven’t built the feedback loops yet.</p><h3 name="fd3e" id="fd3e" class="graf graf--h3 graf-after--p">The testing reality</h3><p name="079c" id="079c" class="graf graf--p graf-after--h3">By the end of June 2, database persistence was working mechanically. Workflows got saved, domain entities had proper relationships, the repository pattern kept data access clean.</p><p name="363b" id="363b" class="graf graf--p graf-after--p">But we discovered something important: persistence without validation is just organized data hoarding. We’d successfully saved workflow results but hadn’t verified that saving them actually enabled better future recommendations.</p><h3 name="b62a" id="b62a" class="graf graf--h3 graf-after--p">SQLAlchemy insights (the technical bits)</h3><p name="e37f" id="e37f" class="graf graf--p graf-after--h3">Some discoveries from the June 2 database implementation:</p><p name="2e76" id="2e76" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">back_populates creates bidirectional relationships automatically.</strong> Set <code class="markup--code markup--p-code">feature.product = X</code> and SQLAlchemy adds the feature to <code class="markup--code markup--p-code">X.features</code> without explicit code.</p><p name="dc06" id="dc06" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">JSON columns enable schema evolution.</strong> Instead of adding new database columns every time we expand PM concepts, we use JSON fields for flexible data that can evolve over time.</p><p name="b788" id="b788" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Async all the way.</strong> Using asyncpg with SQLAlchemy’s async support enables non-blocking database operations. Critical when the AI is processing multiple workflows concurrently.</p><p name="a324" id="a324" class="graf graf--p graf-after--p">Note: I came to loath the string “asyncio” as I tended to see it when tests were failing and it started to feel like we kept fixing async issues all the time. “Ay-sink-ee-oh!” I would groan <em class="markup--em markup--p-em">again</em>, like some sort of demented bizarro bingo player.</p><h3 name="b359" id="b359" class="graf graf--h3 graf-after--p">The compound learning vision (not yet reality)</h3><p name="2085" id="2085" class="graf graf--p graf-after--h3">The goal is <em class="markup--em markup--p-em">compound learning</em>: each interaction teaches the system something about how product work actually happens in your context. After analyzing dozens of feature requests, the AI should recognize patterns like “requests from the enterprise team typically have hidden compliance requirements.”</p><p name="6508" id="6508" class="graf graf--p graf-after--p">That’s the vision. The current reality is more humble: we can store workflow results and query them later. The pattern recognition and insight generation? Still on the roadmap.</p><h3 name="b087" id="b087" class="graf graf--h3 graf-after--p">Current capabilities vs future promises</h3><p name="3608" id="3608" class="graf graf--p graf-after--h3"><strong class="markup--strong markup--p-strong">What actually worked as of June 2:</strong></p><ul class="postList"><li name="316b" id="316b" class="graf graf--li graf-after--p">Structured persistence of workflow executions</li><li name="9758" id="9758" class="graf graf--li graf-after--li">Database queries for historical workflow data</li><li name="8417" id="8417" class="graf graf--li graf-after--li">Proper PM domain modeling in the database</li><li name="9301" id="9301" class="graf graf--li graf-after--li">Repository pattern for clean data access</li></ul><p name="f3df" id="f3df" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">What we were building toward:</strong></p><ul class="postList"><li name="c51e" id="c51e" class="graf graf--li graf-after--p">Learning from workflow outcomes</li><li name="750e" id="750e" class="graf graf--li graf-after--li">Pattern recognition across similar requests</li><li name="8e65" id="8e65" class="graf graf--li graf-after--li">Feedback incorporation to improve recommendations</li><li name="0e96" id="0e96" class="graf graf--li graf-after--li">Cross-project insight generation</li></ul><p name="4b78" id="4b78" class="graf graf--p graf-after--li">The architecture supports the vision, but we’re maybe 20% of the way to genuine learning.</p><h3 name="abff" id="abff" class="graf graf--h3 graf-after--p">The late-night architecture insight</h3><p name="195d" id="195d" class="graf graf--p graf-after--h3">Some of the best discoveries happen during those late coding sessions when your critical brain is tired. Around 11 PM during the June 2 session, I made a decision that turned out to be crucial: store the uncertainty too.</p><p name="1d4a" id="1d4a" class="graf graf--p graf-after--p">When the AI classifies an intent with 0.95 confidence, save that confidence level. When it considers multiple workflow options, save the alternatives it didn’t choose. When it makes assumptions, capture what those assumptions were.</p><p name="37fd" id="37fd" class="graf graf--p graf-after--p">This creates a research dataset about AI decision-making that could be incredibly valuable for improving the system over time.</p><h3 name="8747" id="8747" class="graf graf--h3 graf-after--p">The debugging reality</h3><p name="ed17" id="ed17" class="graf graf--p graf-after--h3">The June 2 session ended with working persistence but some unresolved circular import issues in the orchestration layer. Classic software development: you solve one problem and discover two more.</p><p name="6bd0" id="6bd0" class="graf graf--p graf-after--p">But the foundation was solid. The domain models felt right, the repository pattern kept data access clean, and the database schema could evolve as our understanding of PM concepts deepened.</p><h3 name="e56d" id="e56d" class="graf graf--h3 graf-after--p">What persistence actually enables</h3><p name="744a" id="744a" class="graf graf--p graf-after--h3">With working database persistence, future versions of Piper Morgan could:</p><p name="f9dc" id="f9dc" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Resume interrupted workflows</strong>: “We were analyzing that payment feature before the weekend. Here’s where we left off.”</p><p name="0026" id="0026" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Reference historical decisions</strong>: “The last time we worked on mobile performance, these three approaches worked best.”</p><p name="8157" id="8157" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Track pattern evolution</strong>: “Enterprise feature requests have gotten 40% more complex over the last quarter.”</p><p name="63cd" id="63cd" class="graf graf--p graf-after--p">But that’s conditional on building the learning loops that turn stored data into accumulated wisdom.</p><h3 name="0c79" id="0c79" class="graf graf--h3 graf-after--p">The honest assessment</h3><p name="b0ce" id="b0ce" class="graf graf--p graf-after--h3">Giving AI memory is like giving someone a library card. The potential is enormous, but the value depends on what they do with access to all that information.</p><p name="b795" id="b795" class="graf graf--p graf-after--p">We’ve built the library. The AI can check out books. Whether it becomes genuinely smarter over time… that depends on capabilities we haven’t built yet.</p><p name="94ec" id="94ec" class="graf graf--p graf-after--p graf--trailing">But the foundation is in place. Every workflow execution is captured. Every decision point is logged. When we’re ready to build learning algorithms, we’ll have the data to train them on.</p></div></div></section><section name="ded9" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="f0c9" id="f0c9" class="graf graf--p graf--leading"><em class="markup--em markup--p-em">Next in Building Piper Morgan: How we replaced mock responses with “actual AI intelligence.”</em></p><p name="2378" id="2378" class="graf graf--p graf-after--p graf--trailing"><em class="markup--em markup--p-em">Did you ever wish your tools could remember where you left off and just pick up naturally, the way people (sometimes) can? That’s the dream!</em></p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@mediajunkie" class="p-author h-card">christian crumlish</a> on <a href="https://medium.com/p/d9f839597278"><time class="dt-published" datetime="2025-07-15T13:22:44.210Z">July 15, 2025</time></a>.</p><p><a href="https://medium.com/@mediajunkie/persistence-of-memory-ai-cant-learn-without-it-d9f839597278" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on October 9, 2025.</p></footer></article></body></html>