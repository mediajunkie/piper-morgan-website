1:"$Sreact.fragment"
8:I[8393,[],""]
:HL["/_next/static/css/f9342e94655f11e9.css","style"]
2:T1313,
            :root{--primary-teal:#2DD4BF;--primary-teal-text:#0D9488;--text-dark:#1F2937;--text-light:#6B7280;--background:#FFFFFF;--surface:#F9FAFB}
            .dark{--text-dark:#F1F5F9;--text-light:#94A3B8;--background:#0F172A;--surface:#1E293B}
            @font-face{font-family:'Inter';src:url('/fonts/inter-latin.woff2') format('woff2');font-weight:100 900;font-style:normal;font-display:swap;unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}
            *{box-sizing:border-box}
            html{scroll-behavior:smooth;font-size:16px;margin:0;padding:0;border:none;outline:none}
            body{background:var(--background);color:var(--text-dark);font-family:'Inter',-apple-system,BlinkMacSystemFont,'Segoe UI','Roboto','Oxygen','Ubuntu','Cantarell',sans-serif;line-height:1.6;margin:0;padding:0;border:none;outline:none;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}
            nav{border:none !important;outline:none !important}
            h1,h2,h3,h4,h5,h6{font-family:'Hoss Round','Inter',-apple-system,BlinkMacSystemFont,'Segoe UI',sans-serif}
            p,span{max-width:75ch;line-height:1.7}
            .text-content div{max-width:75ch;line-height:1.7}
            .text-content{max-width:65ch}
            @media (max-width:640px){
              h1{font-size:1.75rem;line-height:1.2}
              h2{font-size:1.25rem;line-height:1.3}
              h3{font-size:1.1rem;line-height:1.4}
              h4{font-size:1rem;line-height:1.4}
            }
            @media (min-width:641px) and (max-width:768px){
              h1{font-size:2rem;line-height:1.2}
              h2{font-size:1.5rem;line-height:1.3}
              h3{font-size:1.25rem;line-height:1.4}
            }
            @media (prefers-reduced-motion: reduce){
              *{animation-duration:0.01ms !important;animation-iteration-count:1 !important;transition-duration:0.01ms !important}
            }
            a:hover{color:#0D9488;transition:color 0.2s ease}
            .hover-lift:hover{transform:translateY(-2px);transition:transform 0.2s ease}
            button:focus,a:focus{outline:2px solid #2DD4BF;outline-offset:2px;border-radius:4px}
            .skip-to-content{position:absolute;top:-100px;left:0;z-index:999;padding:8px 16px;background:#1F2937;color:white;text-decoration:none;border-radius:0 0 4px 0;transition:top 0.3s}
            .skip-to-content:focus{top:0;outline:2px solid #2DD4BF;outline-offset:2px}
            .section-spacing{margin-bottom:4rem}
            .component-spacing{margin-bottom:1.5rem}
            .micro-spacing{margin-bottom:0.5rem}
            @media (min-width:768px){
              .section-spacing{margin-bottom:6rem}
              .component-spacing{margin-bottom:2rem}
            }
            .site-container{width:100%;max-width:1200px;margin-left:auto;margin-right:auto;padding-left:1rem;padding-right:1rem}
            @media (min-width:640px){.site-container{padding-left:1.5rem;padding-right:1.5rem}}
            @media (min-width:768px){.site-container{padding-left:2rem;padding-right:2rem}}
            @media (min-width:1024px){.site-container{max-width:1200px}}
            @media (min-width:1200px){.site-container{max-width:1200px}}
            .section-padding{padding-top:4rem;padding-bottom:4rem}
            @media (min-width:768px){.section-padding{padding-top:5rem;padding-bottom:5rem}}
            .mx-auto{margin-left:auto;margin-right:auto}
            .max-w-4xl{max-width:56rem}
            .pt-16{padding-top:4rem}
            .pb-8{padding-bottom:2rem}
            .px-4{padding-left:1rem;padding-right:1rem}
            .mb-6{margin-bottom:1.5rem}
            .mb-8{margin-bottom:2rem}
            .text-left{text-align:left}
            .text-center{text-align:center}
            .text-primary-teal-text{color:#0F766E}
            .text-text-dark{color:#1F2937}
            .text-text-light{color:#6B7280}
            .font-bold{font-weight:700}
            .text-4xl{font-size:2.25rem;line-height:2.5rem}
            .text-5xl{font-size:3rem;line-height:1}
            .text-6xl{font-size:3.75rem;line-height:1}
            .text-lg{font-size:1.125rem;line-height:1.75rem}
            .text-xl{font-size:1.25rem;line-height:1.75rem}
            .leading-tight{line-height:1.25}
            .leading-relaxed{line-height:1.625}
            .min-h-screen{min-height:100vh}
            @media (min-width:768px){
              .md\:pt-24{padding-top:6rem}
              .md\:pb-12{padding-bottom:3rem}
              .md\:text-5xl{font-size:3rem;line-height:1}
              .md\:text-xl{font-size:1.25rem;line-height:1.75rem}
            }
            @media (min-width:1024px){
              .lg\:text-6xl{font-size:3.75rem;line-height:1}
            }
          0:{"P":null,"b":"FDvoXZJ_3caFysOy_3tjy","p":"","c":["","blog","why-the-future-of-ai-ux",""],"i":false,"f":[[["",{"children":["blog",{"children":[["slug","why-the-future-of-ai-ux","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/f9342e94655f11e9.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","className":"font-inter","children":[["$","head",null,{"children":[["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              (function() {\n                const theme = localStorage.getItem('theme') ||\n                  (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light');\n                if (theme === 'dark') {\n                  document.documentElement.classList.add('dark');\n                  document.body.classList.add('dark');\n                }\n              })();\n            "}}],["$","link",null,{"rel":"dns-prefetch","href":"//pipermorgan.ai"}],["$","link",null,{"rel":"preconnect","href":"https://pipermorgan.ai"}],["$","link",null,{"rel":"preload","as":"image","href":"/assets/pm-logo.png"}],["$","link",null,{"rel":"preload","href":"/fonts/inter-latin.woff2","as":"font","type":"font/woff2","crossOrigin":"anonymous"}],["$","link",null,{"rel":"preload","href":"/fonts/HossRound-Regular.woff2","as":"font","type":"font/woff2","crossOrigin":"anonymous"}],["$","style",null,{"dangerouslySetInnerHTML":{"__html":"$2"}}]]}],"$L3"]}]]}],{"children":["blog","$L4",{"children":[["slug","why-the-future-of-ai-ux","d"],"$L5",{"children":["__PAGE__","$L6",{},null,false]},null,false]},null,false]},null,false],"$L7",false]],"m":"$undefined","G":["$8",[]],"s":false,"S":true}
9:I[9119,["874","static/chunks/874-668c89038fa04eb8.js","212","static/chunks/212-369ef96a260e510f.js","177","static/chunks/app/layout-9ed54623e803ece8.js"],"ClientLayout"]
a:I[7555,[],""]
b:I[1295,[],""]
c:I[6874,["874","static/chunks/874-668c89038fa04eb8.js","212","static/chunks/212-369ef96a260e510f.js","144","static/chunks/144-1b443e029a921717.js","674","static/chunks/674-5f2fa3597c066943.js","831","static/chunks/app/blog/page-666765c672eae567.js"],""]
10:I[9665,[],"OutletBoundary"]
12:I[4911,[],"AsyncMetadataOutlet"]
14:I[9665,[],"ViewportBoundary"]
16:I[9665,[],"MetadataBoundary"]
17:"$Sreact.suspense"
3:["$","body",null,{"className":"font-sans antialiased","children":[["$","$L9",null,{"children":["$","$La",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$Lb",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","div",null,{"className":"min-h-screen","children":["$","div",null,{"className":"site-container max-w-4xl pt-16 md:pt-24 pb-8 md:pb-12 text-center","children":[["$","div",null,{"className":"mb-8","children":[["$","h1",null,{"className":"text-8xl md:text-9xl font-bold text-primary-teal-text mb-4","children":"404"}],["$","h2",null,{"className":"text-3xl md:text-4xl font-semibold text-text-dark mb-4","children":"Page Not Found"}],["$","p",null,{"className":"text-xl text-text-light leading-relaxed max-w-2xl mx-auto","children":"Looks like this page got lost in the AI training data. Don't worry ‚Äì even the best algorithms make mistakes sometimes."}]]}],["$","div",null,{"className":"mb-12","children":[["$","h3",null,{"className":"text-xl font-semibold text-text-dark mb-6","children":"Where would you like to go instead?"}],["$","div",null,{"className":"grid md:grid-cols-2 gap-6 max-w-2xl mx-auto","children":[["$","div",null,{"className":"space-y-4","children":[["$","$Lc",null,{"href":"/","className":"block p-4 bg-surface rounded-card hover:bg-gray-50 transition-colors group","children":[["$","h4",null,{"className":"font-semibold text-text-dark group-hover:text-primary-teal-text","children":"üè† Homepage"}],["$","p",null,{"className":"text-sm text-text-light mt-1","children":"Start from the beginning of our AI PM journey"}]]}],["$","$Lc",null,{"href":"/how-it-works","className":"block p-4 bg-surface rounded-card hover:bg-gray-50 transition-colors group","children":[["$","h4",null,{"className":"font-semibold text-text-dark group-hover:text-primary-teal-text","children":"‚öôÔ∏è How It Works"}],["$","p",null,{"className":"text-sm text-text-light mt-1","children":"Discover our AI-powered product management methodology"}]]}]]}],["$","div",null,{"className":"space-y-4","children":[["$","$Lc",null,{"href":"/what-weve-learned","className":"block p-4 bg-surface rounded-card hover:bg-gray-50 transition-colors group","children":[["$","h4",null,{"className":"font-semibold text-text-dark group-hover:text-primary-teal-text","children":"üí° What We've Learned"}],["$","p",null,{"className":"text-sm text-text-light mt-1","children":"Building-in-public insights and breakthroughs"}]]}],["$","$Lc",null,{"href":"/blog","className":"block p-4 bg-surface rounded-card hover:bg-gray-50 transition-colors group","children":[["$","h4",null,{"className":"font-semibold text-text-dark group-hover:text-primary-teal-text","children":"üìù Journey"}],["$","p",null,{"className":"text-sm text-text-light mt-1","children":"Follow our building-in-public blog posts"}]]}],["$","$Lc",null,{"href":"/get-involved","className":"block p-4 bg-surface rounded-card hover:bg-gray-50 transition-colors group","children":[["$","h4",null,{"className":"font-semibold text-text-dark group-hover:text-primary-teal-text","children":"üöÄ Get Involved"}],["$","p",null,{"className":"text-sm text-text-light mt-1","children":"Join our community and stay updated"}]]}]]}]]}]]}],["$","div",null,{"className":"text-center","children":[["$","p",null,{"className":"text-text-light mb-6","children":"Still can't find what you're looking for?"}],["$","$Lc",null,{"href":"/get-involved","className":"inline-flex items-center justify-center font-semibold transition-all duration-200 focus:outline-none focus:ring-2 focus:ring-offset-2 disabled:opacity-50 disabled:cursor-not-allowed disabled:hover:transform-none bg-primary-teal text-white hover:bg-teal-600 focus:ring-primary-teal shadow-component hover:shadow-component-hover hover:-translate-y-0.5 hover:scale-105 font-bold text-lg px-8 py-4 text-lg rounded-button","aria-label":"$undefined","children":[false,"Get Help & Stay Updated"]}]]}],["$","div",null,{"className":"mt-12 p-6 bg-gray-50 rounded-card max-w-lg mx-auto","children":["$","p",null,{"className":"text-sm text-text-light italic","children":["üí¨ ","$Ld"," \"Even the most sophisticated neural networks occasionally return null. Let's navigate back to more productive paths together!\""]}]}]]}]}],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}],"$Le"]}]
4:["$","$1","c",{"children":[null,["$","$La",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$Lb",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}]
5:["$","$1","c",{"children":[null,["$","$La",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$Lb",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}]
6:["$","$1","c",{"children":["$Lf",null,["$","$L10",null,{"children":["$L11",["$","$L12",null,{"promise":"$@13"}]]}]]}]
7:["$","$1","h",{"children":[null,[["$","$L14",null,{"children":"$L15"}],null],["$","$L16",null,{"children":["$","div",null,{"hidden":true,"children":["$","$17",null,{"fallback":null,"children":"$L18"}]}]}]]}]
19:I[9795,["874","static/chunks/874-668c89038fa04eb8.js","212","static/chunks/212-369ef96a260e510f.js","177","static/chunks/app/layout-9ed54623e803ece8.js"],"default"]
d:["$","strong",null,{"children":"Piper Morgan says:"}]
e:["$","$L19",null,{}]
1a:I[7887,["874","static/chunks/874-668c89038fa04eb8.js","953","static/chunks/app/blog/%5Bslug%5D/page-63f1c4c60df8aece.js"],"BlogPostContent"]
1b:T24a6,<figure><img alt="The specialist robots work together in a kitchen, one timing, one chopping, one cooking while in another scene one robot with eight arms is making a huge mess at the stove" src="https://cdn-images-1.medium.com/max/1024/1*-rihqLO116WVnWKXAKSGRw.png" /><figcaption><em>‚ÄúYou‚Äôre so smart, they said! You can do it all, they¬†said!‚Äù</em></figcaption></figure><p><em>August 20</em></p><p>After months of building with multiple AI agents, a pattern keeps emerging: We create sophisticated systems, lose track of what we built, then rediscover our own achievements through ‚Äúarchaeological‚Äù investigation.</p><p>This recurring cycle of institutional amnesia may be a bug in our process but for today‚Äôs LLM services, it‚Äôs a feature that reveals the real UX challenge ahead.</p><h3>The intelligence plateau and the orchestration valley</h3><p>The AI industry is obsessed with reasoning capabilities. Larger context windows, better chain-of-thought, more sophisticated inference. Meanwhile, anyone actually building with AI faces a different problem entirely: How do you coordinate multiple specialized capabilities without losing your¬†mind?</p><p>Anyone reading this series has the right to question what this process may be doing to my mind at this very¬†moment!</p><p>Yesterday we discovered 599 comprehensive smoke tests we‚Äôd apparently built and then completely forgotten. Saturday we rediscovered attribution systems we‚Äôd implemented but lost track of (in fact, I only just now remembered it again and added it to my notes to include ATTRIBUTION.md to our weekly doc sweep). Two weeks ago we found enterprise-grade feedback APIs sitting in our codebase, unmarked and uncredited.</p><p>The pattern isn‚Äôt forgetfulness‚Ää‚Äî‚Ääit‚Äôs that our tools for building are ahead of our tools for remembering.</p><h3>From brilliant generalists to orchestrated specialists</h3><p>The current paradigm assumes one brilliant AI that can handle anything you throw at it. The emerging paradigm recognizes that specialized tools, properly coordinated, deliver better results than generalist intelligence.</p><p>Our accidental prototype:</p><ul><li><strong>Claude Code:</strong> Architecture and systematic implementation</li><li><strong>Cursor Agent:</strong> Targeted debugging and focused¬†fixes</li><li><strong>Chief of Staff: </strong>Coordination and strategic oversight</li><li><strong>Chief Architect: </strong>Decision-making and system¬†design</li></ul><p>Each agent has different context levels, different strengths, different appropriate use cases. The magic isn‚Äôt in making any individual agent smarter‚Ää‚Äî‚Ääit‚Äôs in the orchestration patterns that let them work together effectively.</p><p>One thing this enables me to do is to have focused coherent conversations and decision-making processes always at the right level of abstraction. Early on I found that as soon as multiple contexts get mixed you get a mishmash of more generic and sloppy advice and results. It‚Äôs kind of like how if you mix too many paints you end up with the same muddy¬†brown.</p><h3>The UX we actually¬†need</h3><p>After coordinating multi-agent workflows for months, I‚Äôm realizing that the UX challenges aren‚Äôt about reasoning‚Ää‚Äî‚Ääthey‚Äôre¬†about:</p><ul><li>Context handoffs: How do you maintain working memory across agent transitions?</li><li>Coordination protocols: How do you deploy the right agent for the right task without overwhelming the human orchestrator?</li><li>Institutional memory: How do you prevent the ‚Äúforgotten monuments‚Äù cycle where sophisticated systems get lost in your own complexity?</li><li>Verification workflows: How do you maintain quality when multiple agents contribute to the same¬†outcome?</li></ul><p>Each of these is critical and urgent in its own way. Getting any of these wrong means you are just injecting chaos into your processes.</p><h3>Throwing intelligence at everything</h3><p>We keep applying intelligence solutions to orchestration problems. Need better coordination? Train a smarter model. Need better memory? Increase context windows. Need better task routing? Build more sophisticated reasoning.</p><p>Except, orchestration isn‚Äôt really an intelligence problem.<em> It‚Äôs a UX design¬†problem</em>.</p><p>My failed adoption of the TLDR system is a perfect illustration. I absorbed something that sounded cool to me without really understanding it was intended to work with 50ms test timeouts from compiled languages, which ignores Python‚Äôs ecosystem realities. More intelligence wouldn‚Äôt have fixed the fundamental mismatch where understanding my constraints better would¬†have.</p><h3>Affordances over algorithms</h3><p>UX for AI will be defined¬†by:</p><p><strong>Specialized models</strong> over generalist LLMs. A focused SLM that understands database schemas will outperform a brilliant generalist that has to reason about every query from first principles.</p><p><strong>Orchestration patterns</strong> over individual agent capabilities. The system that deploys the right specialist at the right time beats the system with the smartest individual components.</p><p><strong>Context management</strong> over context windows. Better handoff protocols matter more than larger memory capacity.</p><p><strong>Coordination affordances </strong>over reasoning power. Tools that help humans orchestrate AI workflows effectively will matter more than tools that make individual AI agents more¬†capable.</p><p>I can‚Äôt even say how these affordances will look or behave. I‚Äôm treading the cowpaths now, and hoping talented UX designers (hey, I‚Äôm just a PM these days!) can figure this out and save me all the manual work and cognitive labor I do to provide resilience and coherence via scaffolding, harness, redundancy, and other the other hacks I‚Äôve been picking up through trial and error (and stealing ideas from other people!).</p><h3>The working memory revolution</h3><p>Our recurring ‚Äúarchaeological discovery‚Äù pattern reveals the real frontier: building systems that maintain institutional memory across time, people, and context switches.</p><p>Every time we rediscover forgotten excellence, we‚Äôre experiencing the same challenge every team building with AI will face: How do you scale human-AI collaboration without losing track of what you‚Äôve accomplished?</p><h3>Orchestration as a new kind of¬†literacy</h3><p>Pretty soon, prompting individual AI agents effectively will stop being the valuable skill (or parlor trick) it is today. What we‚Äôre going to look for is the ability to orchestrate multiple specialized AI capabilities without losing coherence.</p><p>Product managers will need orchestration patterns for coordinating AI-augmented workflows across¬†teams.</p><p>Designers will need to make (and use!) affordances for human-AI collaboration that maintain user agency while leveraging AI capabilities.</p><p>Engineers will need architecture patterns for composing AI services without creating coordination overhead.</p><h3>The Piper Morgan¬†thesis</h3><p>While I am definitely building a product management tool, I find I am also prototyping the UX patterns that are like to define human-AI collaboration, or at least point us in the right direction, over the next¬†decade.</p><p>I always knew this was a learning project. I sincerely want ship v1 of Piper Morgan and deliver value to myself and ideally others as well. At the same time it‚Äôs been incredibly rewarding just plunging in learning things constantly, and then turning around quickly to share my enthusiasm with all of¬†you.</p><p>What I didn‚Äôt realize is that beyond building Piper Morgan, I may be studying just exactly the sort of interesting puzzles and problems and opportunities that the brightest minds in UX and digital software product development need to be figuring out, and fast! (Before the bad guys own it¬†all.)</p><p>My recurring cycle of building sophisticated systems, losing track of them, and rediscovering them through archaeological investigation provides some ongoing comic relief for anyone following along, as well as an endless rollercoaster ride of elation and chagrin for me, and it also happens to be one of the fundamental challenges that every organization building with AI will¬†face.</p><p>Smarter AI isn‚Äôt going to get us there, but better orchestration just¬†might.</p><p><em>Next on Building Piper Morgan, we resume the daily narrative on October 5, When 75% Turns Out to Mean¬†100%.</em></p><p><em>This article was written through multi-agent collaboration, refined through systematic methodology, and documented with full acknowledgment that I‚Äôll probably forget we wrote it and one of my bot pals will rediscover it archaeologically in six months and say ‚ÄúYou have to read this amazing article somebody¬†wrote.‚Äù</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=8aacc89aecc9" width="1" height="1" alt=""><hr><p><a href="https://medium.com/building-piper-morgan/why-the-future-of-ai-ux-is-orchestration-not-intelligence-8aacc89aecc9">Why the Future of AI UX is Orchestration, Not Intelligence</a> was originally published in <a href="https://medium.com/building-piper-morgan">Building Piper Morgan</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>1c:T24a6,<figure><img alt="The specialist robots work together in a kitchen, one timing, one chopping, one cooking while in another scene one robot with eight arms is making a huge mess at the stove" src="https://cdn-images-1.medium.com/max/1024/1*-rihqLO116WVnWKXAKSGRw.png" /><figcaption><em>‚ÄúYou‚Äôre so smart, they said! You can do it all, they¬†said!‚Äù</em></figcaption></figure><p><em>August 20</em></p><p>After months of building with multiple AI agents, a pattern keeps emerging: We create sophisticated systems, lose track of what we built, then rediscover our own achievements through ‚Äúarchaeological‚Äù investigation.</p><p>This recurring cycle of institutional amnesia may be a bug in our process but for today‚Äôs LLM services, it‚Äôs a feature that reveals the real UX challenge ahead.</p><h3>The intelligence plateau and the orchestration valley</h3><p>The AI industry is obsessed with reasoning capabilities. Larger context windows, better chain-of-thought, more sophisticated inference. Meanwhile, anyone actually building with AI faces a different problem entirely: How do you coordinate multiple specialized capabilities without losing your¬†mind?</p><p>Anyone reading this series has the right to question what this process may be doing to my mind at this very¬†moment!</p><p>Yesterday we discovered 599 comprehensive smoke tests we‚Äôd apparently built and then completely forgotten. Saturday we rediscovered attribution systems we‚Äôd implemented but lost track of (in fact, I only just now remembered it again and added it to my notes to include ATTRIBUTION.md to our weekly doc sweep). Two weeks ago we found enterprise-grade feedback APIs sitting in our codebase, unmarked and uncredited.</p><p>The pattern isn‚Äôt forgetfulness‚Ää‚Äî‚Ääit‚Äôs that our tools for building are ahead of our tools for remembering.</p><h3>From brilliant generalists to orchestrated specialists</h3><p>The current paradigm assumes one brilliant AI that can handle anything you throw at it. The emerging paradigm recognizes that specialized tools, properly coordinated, deliver better results than generalist intelligence.</p><p>Our accidental prototype:</p><ul><li><strong>Claude Code:</strong> Architecture and systematic implementation</li><li><strong>Cursor Agent:</strong> Targeted debugging and focused¬†fixes</li><li><strong>Chief of Staff: </strong>Coordination and strategic oversight</li><li><strong>Chief Architect: </strong>Decision-making and system¬†design</li></ul><p>Each agent has different context levels, different strengths, different appropriate use cases. The magic isn‚Äôt in making any individual agent smarter‚Ää‚Äî‚Ääit‚Äôs in the orchestration patterns that let them work together effectively.</p><p>One thing this enables me to do is to have focused coherent conversations and decision-making processes always at the right level of abstraction. Early on I found that as soon as multiple contexts get mixed you get a mishmash of more generic and sloppy advice and results. It‚Äôs kind of like how if you mix too many paints you end up with the same muddy¬†brown.</p><h3>The UX we actually¬†need</h3><p>After coordinating multi-agent workflows for months, I‚Äôm realizing that the UX challenges aren‚Äôt about reasoning‚Ää‚Äî‚Ääthey‚Äôre¬†about:</p><ul><li>Context handoffs: How do you maintain working memory across agent transitions?</li><li>Coordination protocols: How do you deploy the right agent for the right task without overwhelming the human orchestrator?</li><li>Institutional memory: How do you prevent the ‚Äúforgotten monuments‚Äù cycle where sophisticated systems get lost in your own complexity?</li><li>Verification workflows: How do you maintain quality when multiple agents contribute to the same¬†outcome?</li></ul><p>Each of these is critical and urgent in its own way. Getting any of these wrong means you are just injecting chaos into your processes.</p><h3>Throwing intelligence at everything</h3><p>We keep applying intelligence solutions to orchestration problems. Need better coordination? Train a smarter model. Need better memory? Increase context windows. Need better task routing? Build more sophisticated reasoning.</p><p>Except, orchestration isn‚Äôt really an intelligence problem.<em> It‚Äôs a UX design¬†problem</em>.</p><p>My failed adoption of the TLDR system is a perfect illustration. I absorbed something that sounded cool to me without really understanding it was intended to work with 50ms test timeouts from compiled languages, which ignores Python‚Äôs ecosystem realities. More intelligence wouldn‚Äôt have fixed the fundamental mismatch where understanding my constraints better would¬†have.</p><h3>Affordances over algorithms</h3><p>UX for AI will be defined¬†by:</p><p><strong>Specialized models</strong> over generalist LLMs. A focused SLM that understands database schemas will outperform a brilliant generalist that has to reason about every query from first principles.</p><p><strong>Orchestration patterns</strong> over individual agent capabilities. The system that deploys the right specialist at the right time beats the system with the smartest individual components.</p><p><strong>Context management</strong> over context windows. Better handoff protocols matter more than larger memory capacity.</p><p><strong>Coordination affordances </strong>over reasoning power. Tools that help humans orchestrate AI workflows effectively will matter more than tools that make individual AI agents more¬†capable.</p><p>I can‚Äôt even say how these affordances will look or behave. I‚Äôm treading the cowpaths now, and hoping talented UX designers (hey, I‚Äôm just a PM these days!) can figure this out and save me all the manual work and cognitive labor I do to provide resilience and coherence via scaffolding, harness, redundancy, and other the other hacks I‚Äôve been picking up through trial and error (and stealing ideas from other people!).</p><h3>The working memory revolution</h3><p>Our recurring ‚Äúarchaeological discovery‚Äù pattern reveals the real frontier: building systems that maintain institutional memory across time, people, and context switches.</p><p>Every time we rediscover forgotten excellence, we‚Äôre experiencing the same challenge every team building with AI will face: How do you scale human-AI collaboration without losing track of what you‚Äôve accomplished?</p><h3>Orchestration as a new kind of¬†literacy</h3><p>Pretty soon, prompting individual AI agents effectively will stop being the valuable skill (or parlor trick) it is today. What we‚Äôre going to look for is the ability to orchestrate multiple specialized AI capabilities without losing coherence.</p><p>Product managers will need orchestration patterns for coordinating AI-augmented workflows across¬†teams.</p><p>Designers will need to make (and use!) affordances for human-AI collaboration that maintain user agency while leveraging AI capabilities.</p><p>Engineers will need architecture patterns for composing AI services without creating coordination overhead.</p><h3>The Piper Morgan¬†thesis</h3><p>While I am definitely building a product management tool, I find I am also prototyping the UX patterns that are like to define human-AI collaboration, or at least point us in the right direction, over the next¬†decade.</p><p>I always knew this was a learning project. I sincerely want ship v1 of Piper Morgan and deliver value to myself and ideally others as well. At the same time it‚Äôs been incredibly rewarding just plunging in learning things constantly, and then turning around quickly to share my enthusiasm with all of¬†you.</p><p>What I didn‚Äôt realize is that beyond building Piper Morgan, I may be studying just exactly the sort of interesting puzzles and problems and opportunities that the brightest minds in UX and digital software product development need to be figuring out, and fast! (Before the bad guys own it¬†all.)</p><p>My recurring cycle of building sophisticated systems, losing track of them, and rediscovering them through archaeological investigation provides some ongoing comic relief for anyone following along, as well as an endless rollercoaster ride of elation and chagrin for me, and it also happens to be one of the fundamental challenges that every organization building with AI will¬†face.</p><p>Smarter AI isn‚Äôt going to get us there, but better orchestration just¬†might.</p><p><em>Next on Building Piper Morgan, we resume the daily narrative on October 5, When 75% Turns Out to Mean¬†100%.</em></p><p><em>This article was written through multi-agent collaboration, refined through systematic methodology, and documented with full acknowledgment that I‚Äôll probably forget we wrote it and one of my bot pals will rediscover it archaeologically in six months and say ‚ÄúYou have to read this amazing article somebody¬†wrote.‚Äù</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=8aacc89aecc9" width="1" height="1" alt=""><hr><p><a href="https://medium.com/building-piper-morgan/why-the-future-of-ai-ux-is-orchestration-not-intelligence-8aacc89aecc9">Why the Future of AI UX is Orchestration, Not Intelligence</a> was originally published in <a href="https://medium.com/building-piper-morgan">Building Piper Morgan</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>f:["$","$L1a",null,{"post":{"title":"Why the Future of AI UX is Orchestration, Not Intelligence","excerpt":"‚ÄúYou‚Äôre so smart, they said! You can do it all, they said!‚ÄùAugust 20After months of building with multiple AI agents, a pattern keeps emerging: We create sophisticated systems, lose track of what we built, then rediscover our own achievements through ‚Äúarchaeological‚Äù investigation.This recurring ...","url":"/blog/why-the-future-of-ai-ux","publishedAt":"Oct 12, 2025","publishedAtISO":"Sun, 12 Oct 2025 13:37:57 GMT","author":"christian crumlish","readingTime":"5 min read","tags":["Building in Public"],"guid":"https://medium.com/p/8aacc89aecc9","featuredImage":"https://cdn-images-1.medium.com/max/1024/1*-rihqLO116WVnWKXAKSGRw.png","fullContent":"$1b","subtitle":"","canonicalLink":"https://medium.com/building-piper-morgan/why-the-future-of-ai-ux-is-orchestration-not-intelligence-8aacc89aecc9?source=rss----982e21163f8b---4","thumbnail":"/assets/blog-images/8aacc89aecc9-featured.png","slug":"why-the-future-of-ai-ux","workDate":"Aug 19, 2025","workDateISO":"2025-08-19T00:00:00.000Z","category":"insight","cluster":"reflection-evolution","featured":false},"content":{"title":"Why the Future of AI UX is Orchestration, Not Intelligence","subtitle":"","content":"$1c","author":"christian crumlish","canonicalLink":"https://medium.com/building-piper-morgan/why-the-future-of-ai-ux-is-orchestration-not-intelligence-8aacc89aecc9?source=rss----982e21163f8b---4","publishedDate":"2025-10-12T13:37:57.000Z","filename":"rss-8aacc89aecc9.html"}}]
15:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
11:null
1d:I[8175,[],"IconMark"]
13:{"metadata":[["$","title","0",{"children":"Why the Future of AI UX is Orchestration, Not Intelligence | Piper Morgan"}],["$","meta","1",{"name":"author","content":"Christian Crumlish"}],["$","meta","2",{"name":"keywords","content":"AI,Product Management,Methodology,Building in Public"}],["$","meta","3",{"name":"creator","content":"Christian Crumlish"}],["$","meta","4",{"name":"publisher","content":"Christian Crumlish"}],["$","meta","5",{"name":"robots","content":"index, follow"}],["$","meta","6",{"name":"googlebot","content":"index, follow"}],["$","link","7",{"rel":"canonical","href":"https://pipermorgan.ai/"}],["$","meta","8",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","9",{"property":"og:title","content":"Why the Future of AI UX is Orchestration, Not Intelligence"}],["$","meta","10",{"property":"og:image","content":"https://pipermorgan.ai/assets/blog-images/8aacc89aecc9-featured.png"}],["$","meta","11",{"property":"og:type","content":"article"}],["$","meta","12",{"property":"article:author","content":"christian crumlish"}],["$","meta","13",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","14",{"name":"twitter:title","content":"Why the Future of AI UX is Orchestration, Not Intelligence"}],["$","meta","15",{"name":"twitter:image","content":"https://pipermorgan.ai/assets/blog-images/8aacc89aecc9-featured.png"}],["$","link","16",{"rel":"icon","href":"/favicon.ico","type":"image/x-icon","sizes":"32x33"}],["$","link","17",{"rel":"icon","href":"/favicon.ico","sizes":"32x32","type":"image/x-icon"}],["$","link","18",{"rel":"icon","href":"/pm-favicon-16.png","sizes":"16x16","type":"image/png"}],["$","link","19",{"rel":"icon","href":"/pm-favicon-32.png","sizes":"32x32","type":"image/png"}],["$","link","20",{"rel":"icon","href":"/pm-favicon-48.png","sizes":"48x48","type":"image/png"}],["$","link","21",{"rel":"apple-touch-icon","href":"/pm-favicon-180.png","sizes":"180x180","type":"image/png"}],["$","link","22",{"rel":"icon","href":"/pm-favicon-192.png","sizes":"192x192","type":"image/png"}],["$","$L1d","23",{}]],"error":null,"digest":"$undefined"}
18:"$13:metadata"
