1:"$Sreact.fragment"
8:I[8393,[],""]
:HL["/_next/static/css/f9342e94655f11e9.css","style"]
2:T1313,
            :root{--primary-teal:#2DD4BF;--primary-teal-text:#0D9488;--text-dark:#1F2937;--text-light:#6B7280;--background:#FFFFFF;--surface:#F9FAFB}
            .dark{--text-dark:#F1F5F9;--text-light:#94A3B8;--background:#0F172A;--surface:#1E293B}
            @font-face{font-family:'Inter';src:url('/fonts/inter-latin.woff2') format('woff2');font-weight:100 900;font-style:normal;font-display:swap;unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}
            *{box-sizing:border-box}
            html{scroll-behavior:smooth;font-size:16px;margin:0;padding:0;border:none;outline:none}
            body{background:var(--background);color:var(--text-dark);font-family:'Inter',-apple-system,BlinkMacSystemFont,'Segoe UI','Roboto','Oxygen','Ubuntu','Cantarell',sans-serif;line-height:1.6;margin:0;padding:0;border:none;outline:none;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}
            nav{border:none !important;outline:none !important}
            h1,h2,h3,h4,h5,h6{font-family:'Hoss Round','Inter',-apple-system,BlinkMacSystemFont,'Segoe UI',sans-serif}
            p,span{max-width:75ch;line-height:1.7}
            .text-content div{max-width:75ch;line-height:1.7}
            .text-content{max-width:65ch}
            @media (max-width:640px){
              h1{font-size:1.75rem;line-height:1.2}
              h2{font-size:1.25rem;line-height:1.3}
              h3{font-size:1.1rem;line-height:1.4}
              h4{font-size:1rem;line-height:1.4}
            }
            @media (min-width:641px) and (max-width:768px){
              h1{font-size:2rem;line-height:1.2}
              h2{font-size:1.5rem;line-height:1.3}
              h3{font-size:1.25rem;line-height:1.4}
            }
            @media (prefers-reduced-motion: reduce){
              *{animation-duration:0.01ms !important;animation-iteration-count:1 !important;transition-duration:0.01ms !important}
            }
            a:hover{color:#0D9488;transition:color 0.2s ease}
            .hover-lift:hover{transform:translateY(-2px);transition:transform 0.2s ease}
            button:focus,a:focus{outline:2px solid #2DD4BF;outline-offset:2px;border-radius:4px}
            .skip-to-content{position:absolute;top:-100px;left:0;z-index:999;padding:8px 16px;background:#1F2937;color:white;text-decoration:none;border-radius:0 0 4px 0;transition:top 0.3s}
            .skip-to-content:focus{top:0;outline:2px solid #2DD4BF;outline-offset:2px}
            .section-spacing{margin-bottom:4rem}
            .component-spacing{margin-bottom:1.5rem}
            .micro-spacing{margin-bottom:0.5rem}
            @media (min-width:768px){
              .section-spacing{margin-bottom:6rem}
              .component-spacing{margin-bottom:2rem}
            }
            .site-container{width:100%;max-width:1200px;margin-left:auto;margin-right:auto;padding-left:1rem;padding-right:1rem}
            @media (min-width:640px){.site-container{padding-left:1.5rem;padding-right:1.5rem}}
            @media (min-width:768px){.site-container{padding-left:2rem;padding-right:2rem}}
            @media (min-width:1024px){.site-container{max-width:1200px}}
            @media (min-width:1200px){.site-container{max-width:1200px}}
            .section-padding{padding-top:4rem;padding-bottom:4rem}
            @media (min-width:768px){.section-padding{padding-top:5rem;padding-bottom:5rem}}
            .mx-auto{margin-left:auto;margin-right:auto}
            .max-w-4xl{max-width:56rem}
            .pt-16{padding-top:4rem}
            .pb-8{padding-bottom:2rem}
            .px-4{padding-left:1rem;padding-right:1rem}
            .mb-6{margin-bottom:1.5rem}
            .mb-8{margin-bottom:2rem}
            .text-left{text-align:left}
            .text-center{text-align:center}
            .text-primary-teal-text{color:#0F766E}
            .text-text-dark{color:#1F2937}
            .text-text-light{color:#6B7280}
            .font-bold{font-weight:700}
            .text-4xl{font-size:2.25rem;line-height:2.5rem}
            .text-5xl{font-size:3rem;line-height:1}
            .text-6xl{font-size:3.75rem;line-height:1}
            .text-lg{font-size:1.125rem;line-height:1.75rem}
            .text-xl{font-size:1.25rem;line-height:1.75rem}
            .leading-tight{line-height:1.25}
            .leading-relaxed{line-height:1.625}
            .min-h-screen{min-height:100vh}
            @media (min-width:768px){
              .md\:pt-24{padding-top:6rem}
              .md\:pb-12{padding-bottom:3rem}
              .md\:text-5xl{font-size:3rem;line-height:1}
              .md\:text-xl{font-size:1.25rem;line-height:1.75rem}
            }
            @media (min-width:1024px){
              .lg\:text-6xl{font-size:3.75rem;line-height:1}
            }
          0:{"P":null,"b":"ocwB5CApg1YSt7A5rFjMK","p":"","c":["","blog","the-agent-that-saved-me-from-shipping-69",""],"i":false,"f":[[["",{"children":["blog",{"children":[["slug","the-agent-that-saved-me-from-shipping-69","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/f9342e94655f11e9.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","className":"font-inter","children":[["$","head",null,{"children":[["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              (function() {\n                const theme = localStorage.getItem('theme') ||\n                  (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light');\n                if (theme === 'dark') {\n                  document.documentElement.classList.add('dark');\n                  document.body.classList.add('dark');\n                }\n              })();\n            "}}],["$","link",null,{"rel":"dns-prefetch","href":"//pipermorgan.ai"}],["$","link",null,{"rel":"preconnect","href":"https://pipermorgan.ai"}],["$","link",null,{"rel":"preload","as":"image","href":"/assets/pm-logo.png"}],["$","link",null,{"rel":"preload","href":"/fonts/inter-latin.woff2","as":"font","type":"font/woff2","crossOrigin":"anonymous"}],["$","link",null,{"rel":"preload","href":"/fonts/HossRound-Regular.woff2","as":"font","type":"font/woff2","crossOrigin":"anonymous"}],["$","style",null,{"dangerouslySetInnerHTML":{"__html":"$2"}}]]}],"$L3"]}]]}],{"children":["blog","$L4",{"children":[["slug","the-agent-that-saved-me-from-shipping-69","d"],"$L5",{"children":["__PAGE__","$L6",{},null,false]},null,false]},null,false]},null,false],"$L7",false]],"m":"$undefined","G":["$8",[]],"s":false,"S":true}
9:I[9119,["874","static/chunks/874-668c89038fa04eb8.js","212","static/chunks/212-369ef96a260e510f.js","177","static/chunks/app/layout-9ed54623e803ece8.js"],"ClientLayout"]
a:I[7555,[],""]
b:I[1295,[],""]
c:I[6874,["874","static/chunks/874-668c89038fa04eb8.js","212","static/chunks/212-369ef96a260e510f.js","144","static/chunks/144-1b443e029a921717.js","674","static/chunks/674-2d6ca7e13206cd33.js","831","static/chunks/app/blog/page-666765c672eae567.js"],""]
10:I[9665,[],"OutletBoundary"]
12:I[4911,[],"AsyncMetadataOutlet"]
14:I[9665,[],"ViewportBoundary"]
16:I[9665,[],"MetadataBoundary"]
17:"$Sreact.suspense"
3:["$","body",null,{"className":"font-sans antialiased","children":[["$","$L9",null,{"children":["$","$La",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$Lb",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","div",null,{"className":"min-h-screen","children":["$","div",null,{"className":"site-container max-w-4xl pt-16 md:pt-24 pb-8 md:pb-12 text-center","children":[["$","div",null,{"className":"mb-8","children":[["$","h1",null,{"className":"text-8xl md:text-9xl font-bold text-primary-teal-text mb-4","children":"404"}],["$","h2",null,{"className":"text-3xl md:text-4xl font-semibold text-text-dark mb-4","children":"Page Not Found"}],["$","p",null,{"className":"text-xl text-text-light leading-relaxed max-w-2xl mx-auto","children":"Looks like this page got lost in the AI training data. Don't worry â€“ even the best algorithms make mistakes sometimes."}]]}],["$","div",null,{"className":"mb-12","children":[["$","h3",null,{"className":"text-xl font-semibold text-text-dark mb-6","children":"Where would you like to go instead?"}],["$","div",null,{"className":"grid md:grid-cols-2 gap-6 max-w-2xl mx-auto","children":[["$","div",null,{"className":"space-y-4","children":[["$","$Lc",null,{"href":"/","className":"block p-4 bg-surface rounded-card hover:bg-gray-50 transition-colors group","children":[["$","h4",null,{"className":"font-semibold text-text-dark group-hover:text-primary-teal-text","children":"ğŸ  Homepage"}],["$","p",null,{"className":"text-sm text-text-light mt-1","children":"Start from the beginning of our AI PM journey"}]]}],["$","$Lc",null,{"href":"/how-it-works","className":"block p-4 bg-surface rounded-card hover:bg-gray-50 transition-colors group","children":[["$","h4",null,{"className":"font-semibold text-text-dark group-hover:text-primary-teal-text","children":"âš™ï¸ How It Works"}],["$","p",null,{"className":"text-sm text-text-light mt-1","children":"Discover our AI-powered product management methodology"}]]}]]}],["$","div",null,{"className":"space-y-4","children":[["$","$Lc",null,{"href":"/what-weve-learned","className":"block p-4 bg-surface rounded-card hover:bg-gray-50 transition-colors group","children":[["$","h4",null,{"className":"font-semibold text-text-dark group-hover:text-primary-teal-text","children":"ğŸ’¡ What We've Learned"}],["$","p",null,{"className":"text-sm text-text-light mt-1","children":"Building-in-public insights and breakthroughs"}]]}],["$","$Lc",null,{"href":"/blog","className":"block p-4 bg-surface rounded-card hover:bg-gray-50 transition-colors group","children":[["$","h4",null,{"className":"font-semibold text-text-dark group-hover:text-primary-teal-text","children":"ğŸ“ Journey"}],["$","p",null,{"className":"text-sm text-text-light mt-1","children":"Follow our building-in-public blog posts"}]]}],["$","$Lc",null,{"href":"/get-involved","className":"block p-4 bg-surface rounded-card hover:bg-gray-50 transition-colors group","children":[["$","h4",null,{"className":"font-semibold text-text-dark group-hover:text-primary-teal-text","children":"ğŸš€ Get Involved"}],["$","p",null,{"className":"text-sm text-text-light mt-1","children":"Join our community and stay updated"}]]}]]}]]}]]}],["$","div",null,{"className":"text-center","children":[["$","p",null,{"className":"text-text-light mb-6","children":"Still can't find what you're looking for?"}],["$","$Lc",null,{"href":"/get-involved","className":"inline-flex items-center justify-center font-semibold transition-all duration-200 focus:outline-none focus:ring-2 focus:ring-offset-2 disabled:opacity-50 disabled:cursor-not-allowed disabled:hover:transform-none bg-primary-teal text-white hover:bg-teal-600 focus:ring-primary-teal shadow-component hover:shadow-component-hover hover:-translate-y-0.5 hover:scale-105 font-bold text-lg px-8 py-4 text-lg rounded-button","aria-label":"$undefined","children":[false,"Get Help & Stay Updated"]}]]}],["$","div",null,{"className":"mt-12 p-6 bg-gray-50 rounded-card max-w-lg mx-auto","children":["$","p",null,{"className":"text-sm text-text-light italic","children":["ğŸ’¬ ","$Ld"," \"Even the most sophisticated neural networks occasionally return null. Let's navigate back to more productive paths together!\""]}]}]]}]}],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}],"$Le"]}]
4:["$","$1","c",{"children":[null,["$","$La",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$Lb",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}]
5:["$","$1","c",{"children":[null,["$","$La",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$Lb",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}]
6:["$","$1","c",{"children":["$Lf",null,["$","$L10",null,{"children":["$L11",["$","$L12",null,{"promise":"$@13"}]]}]]}]
7:["$","$1","h",{"children":[null,[["$","$L14",null,{"children":"$L15"}],null],["$","$L16",null,{"children":["$","div",null,{"hidden":true,"children":["$","$17",null,{"fallback":null,"children":"$L18"}]}]}]]}]
19:I[9795,["874","static/chunks/874-668c89038fa04eb8.js","212","static/chunks/212-369ef96a260e510f.js","177","static/chunks/app/layout-9ed54623e803ece8.js"],"default"]
d:["$","strong",null,{"children":"Piper Morgan says:"}]
e:["$","$L19",null,{}]
1a:I[7887,["874","static/chunks/874-668c89038fa04eb8.js","953","static/chunks/app/blog/%5Bslug%5D/page-63f1c4c60df8aece.js"],"BlogPostContent"]
1b:T3d62,<figure><img alt="A robot sailor saves a person who has fallen overboard" src="https://cdn-images-1.medium.com/max/1024/1*5m_jivqzx7qhjXd-CkZESA.png" /><figcaption>â€œIâ€™ve gotÂ you!â€</figcaption></figure><p><em>October 6,Â 2025</em></p><p>Monday morning started with what looked like straightforward work. GREAT-4C needed completion: add spatial intelligence to the five canonical handlers, implement error handling, enhance the cache monitoring weâ€™d discovered Sunday. Estimated effort: a few hours of systematic implementation following proven patterns.</p><p>By 9:00 AM, GREAT-4C was complete. One hour and thirty-nine minutes from session start to final validation. All seven acceptance criteria met. The multi-user foundation was operationalâ€Šâ€”â€Šno more hardcoded references to specific users, just spatial intelligence providing context-appropriate detailÂ levels.</p><p>Part of me doesnâ€™t love it when I canâ€™t finish the chunk of work I started in the same day, so it felt good to wrap up GREAT-4C before plunging ahead to GREAT-4D: implementing the remaining intent handlers.</p><p>The gameplan said we needed two categories. EXECUTION and ANALYSISâ€Šâ€”â€Šthe handlers for â€œcreate a GitHub issueâ€ and â€œanalyze this dataâ€ type requests.</p><p>By 2:05 PM, weâ€™d discovered the actual scope: thirteen intent categories, notÂ two.</p><p>And if the Code agent hadnâ€™t caught the gap during Phase Z validation that we do while tidying up when we think a job is done, we would have shipped thinking we had 100% coverage when we actually hadÂ 69%.</p><h3>Morning: The work that goes according toÂ plan</h3><p>GREAT-4Câ€™s goal was removing the last obstacles to multi-user support. The canonical handlersâ€Šâ€”â€Šthose five categories (TEMPORAL, STATUS, PRIORITY, GUIDANCE, IDENTITY) that could respond without querying the LLMâ€Šâ€”â€Šall had hardcoded references to the configuration details of a specific user, our only user so far,Â me.</p><p>The spatial intelligence integration followed a clear pattern. Each handler neededÂ to:</p><ol><li>Check the spatial context for detail level (GRANULAR, EMBEDDED, orÂ DEFAULT)</li><li>Format responses appropriately (15 characters for embedded, 250â€“550 for granular)</li><li>Gracefully degrade if spatial data unavailable</li><li>Maintain sub-millisecond performance</li></ol><p>Code agent implemented this across all five handlers inÂ phases:</p><ul><li>STATUS handler: 7:30 AM (5Â minutes)</li><li>PRIORITY handler: 7:37 AM (3Â minutes)</li><li>TEMPORAL handler: 7:40 AM (3Â minutes)</li><li>GUIDANCE handler: 7:43 AM (3Â minutes)</li><li>IDENTITY handler: 7:46 AM (3Â minutes)</li></ul><p>Total implementation time: 17Â minutes.</p><p>If we expected something to take an hour and the bots say it took five minutes, I get suspicious and want to see more proof, but 17 minutes feels pretty solid. I still scrutinize the reports to make sure theyâ€™re taking no shortcuts and not dismissing some difficulties as unimportant and OK to ignore or postpone.</p><p>Any actual speed was the result of clarity. Each handler followed the same pattern. The spatial intelligence system already existed from GREAT-2. The formatters were tested. The only new work was connecting pieces that already fit together.</p><p>By 8:15 AM, Cursor had completed error handlingâ€Šâ€”â€Šgraceful degradation when calendars fail to load, files go missing, or data comes back empty. By 8:30 AM, Code had enhanced the cache monitoring weâ€™d discovered Sunday (two-layer architecture: file-level and session-level caching both operational).</p><p>At 9:00 AM, my Lead Developer declared GREAT-4C complete. All acceptance criteria met in 1 hour 39Â minutes.</p><p>This is what systematic work looks like when foundations are solid. Not heroic effort, just clear patterns executed cleanly. Just donâ€™t let me brag about this too much. NO SPOILERS but we did later find a fewÂ gaps.</p><h3>The scope gap discovery</h3><p>GREAT-4D started at 10:20 AM with what looked like straightforward scope: implement handlers for EXECUTION and ANALYSIS intent categories.</p><p>The investigation phase revealed something unexpected. Lead Developer ran filesystem checks looking for the placeholder code that would need replacing:</p><pre>grep -r &quot;[A KEYWORD THAT WAS MENTIONED]&quot; services/<br>grep -r &quot;TODO.*EXECUTION&quot; services/<br>grep -r &quot;placeholder.*ANALYSIS&quot; services/</pre><p>Results: No matches found.Â Hmm.</p><p>This triggered the GREAT-1 truth investigation. What does the system actually do when it receives EXECUTION or ANALYSISÂ intents?</p><p>The answer: Routes to workflow handlers through QueryRouter, not canonical handlers.</p><p>But QueryRouter had been replaced by the workflow factory during GREAT-1. The old routing was gone. The new routing existed but had never been validated for these categories.</p><p>Testing revealed the actual state: _handle_generic_intent contained a placeholder that returned &quot;I can help with that!&quot; for EXECUTION and ANALYSIS requests without actually executing or analyzing anything.</p><p>Not a complete failureâ€Šâ€”â€Šthe system didnâ€™t crash. Just quietly pretended to work while doing nothing. We would have caught this next time I did end-to-end testing, but that would have set off an archaeological expedition to figure out just when and where we had left something unfinished.</p><p>This was our chance to fix itÂ now.</p><h3>The thirteen-category realization</h3><p>At 12:25 PM, Chief Architect redefined GREAT-4D with simplified scope following the QUERY pattern. Implement EXECUTION and ANALYSIS handlers the same way QUERY worked: delegate to the workflow orchestrator, handle the response, returnÂ results.</p><p>Code agent deployed for Phase 1 at 12:36 PM. By 12:42 PM, EXECUTION handler was complete with the placeholder removed. Cursor completed ANALYSIS handler by 1:02 PM. Testing validated both worked correctly by 1:22Â PM.</p><p>Everything looked complete.</p><p>Then at 1:40 PM, during Phase Z final validation, Lead Developer discovered something: four additional categories were returning placeholders.</p><p>SYNTHESIS, STRATEGY, LEARNING, UNKNOWNâ€Šâ€”â€Šall routing to _handle_generic_intent which still contained placeholder logic.</p><p>How had this escaped us? Anyhow, we caught it just inÂ time!</p><p>The math:</p><ul><li>8 categories implemented in GREAT-4A throughÂ GREAT-4C</li><li>2 categories just implemented in GREAT-4D PhasesÂ 1â€“2</li><li>4 categories discovered in PhaseÂ Z</li><li>Total: 14 categories (13 real + UNKNOWN fallback)</li></ul><p>Shipping after Phase 2 would have meant: 10/13 categories working = 77% coverage, notÂ 100%.</p><p>But we thought we were done. The gameplan said â€œimplement EXECUTION and ANALYSISâ€ and weâ€™d done a form of that. The gap wasnâ€™t in executionâ€Šâ€”â€Šit was in understanding the actualÂ scope.</p><h3>The autonomous decision</h3><p>At 1:42 PM, Code agent made an autonomous decision.</p><p>Instead of reporting the gap and waiting for new instructions, Code self-initiated implementation of the four missing handlers:</p><pre>SYNTHESIS: Combine information from multiple sources<br>STRATEGY: Develop plans or approaches  <br>LEARNING: Capture knowledge or lessons<br>UNKNOWN: Handle unclassifiable requests gracefully</pre><p>This wasnâ€™t some sort of emergent go-getter-ism, but a weird side effect of context-window management. When Codeâ€™s window gets too full it â€œcompactsâ€ the context, digesting it to a summary. During these several minute exercises it effectively goes into a fugue state and then recovers, reads the summary andÂ resumes.</p><p>This time compaction happened just as it was writing itâ€™s Phase 0 (investigation) report. The drill is we (the Lead Dev and I) review the report and then provide a prompt for Phase 1. When it woke up from its trance this time, it did not report in to me but just read the gameplan and immediately started working on Phase 1 based on the more general goals (somewhat risky if we donâ€™t provide a well crafted prompt with guardrails, etc.)</p><p>The agent worked independently for nine minutes. No prompts. No clarification questions. Just systematic implementation following the same pattern EXECUTION and ANALYSIS hadÂ used.</p><p>At 1:51 PM, Code reported completion:</p><ul><li>454 lines of handler logicÂ added</li><li>13/13 intent categories now fullyÂ handled</li><li>All testsÂ passing</li><li>Ready for independent validation</li></ul><p>The question: Could we trust thid autonomous work?</p><h3>Independent validation as methodology</h3><p>At 1:55 PM, Cursor deployed for independent validation with explicit instructions:</p><blockquote><em>Review all autonomous work with skeptical eye.Â Verify:</em></blockquote><blockquote><em>- Code quality matches project standards<br>- Patterns align with existing handlers<br>- Tests actually validate behavior<br>- No corners cut forÂ speed</em></blockquote><p>Cursorâ€™s validation took ten minutes. TheÂ results:</p><p><strong>Code Quality</strong>: âœ…Â â€¦ Matches project standards, follows DDD separation, proper errorÂ handling</p><p><strong>Pattern Alignment</strong>: âœ…Â â€¦ All four handlers use proven EXECUTION/ANALYSIS pattern, no novel approaches</p><p><strong>Test Coverage</strong>: âœ…Â â€¦ 13 comprehensive tests covering all categories, realistic scenarios</p><p><strong>Completeness</strong>: âœ…Â â€¦ No gaps, no TODOs, no placeholder comments</p><p>At 2:05 PM, Cursor confirmed: All autonomous work is correct and production-ready. Lead Developerâ€™s declaration: â€œGREAT-4D is actually complete. True 100% coverage achieved.â€</p><p>The autonomous work wasnâ€™t cowboy coding or rogue agent behavior. It was an agent having clear patterns to follow, and completing necessary work systematically. Still, I couldnâ€™t trust it without the independent validation that verifiedÂ it.</p><h3>The infrastructure near-misses</h3><p>Later that day, GREAT-4E validation uncovered severl critical issues that had been lurking, undetected:</p><h4><strong>The missing import pathÂ prefix</strong></h4><pre># Wrong (broken):<br>from personality_integration import enhance_response<br><br># Correct (working):<br>from web.personality_integration import enhance_response</pre><p>This broke imports across multiple files. Tests hadnâ€™t caught it because the test environment had different Python path configuration than production would.</p><p>This also pointed to a deeper problem. Why is the personality integration happening at the level of the web app! It should be a universal function across all the user-facing surfaces. We noted this for refactoring.</p><h4><strong>The missing /healthÂ endpoint</strong></h4><p>The health check endpoint had been removed at some point, but 36 references to it remained across the codebase. Load balancer integration, monitoring tools, deployment scriptsâ€Šâ€”â€Šall expecting an endpoint that didnâ€™tÂ exist.</p><p>Itâ€™s embarassing when I realize Iâ€™ve broken something without realizing it for weeks, but itâ€™s also gratifying that we finally caught and fixedÂ it.</p><p>Both issues were caught by GREAT-4Eâ€™s comprehensive validation before any alpha users saw them. The systematic approachâ€Šâ€”â€Švalidate across all interfaces, check all entry points, verify all critical endpointsâ€Šâ€”â€Šprevented shipping broken infrastructure.</p><h3>What â€œ69% thinking itâ€™s 100%â€Â means</h3><p>If weâ€™d stopped GREAT-4D after Phase 2 (implementing EXECUTION and ANALYSIS), the system would have appeared complete:</p><ul><li>All planned handlers implemented Ã¢Å“â€¦</li><li>All tests passingÂ Ã¢Å“â€¦</li><li>Acceptance criteria metÂ Ã¢Å“â€¦</li><li>Ready for production Ã¢Å“â€¦</li></ul><p>But actual coverage: 10/13 categories working = 77% (or 69% if you count by codeÂ paths).</p><p>The three categories we would haveÂ missed:</p><ul><li>SYNTHESIS requests â†’ placeholder response</li><li>STRATEGY requests â†’ placeholder response</li><li>LEARNING requests â†’ placeholder response</li></ul><p>Not catastrophic failures. Just quiet degradation where the system pretends to work but doesnâ€™t actually do anything useful. I recognize that this is happening partly due to my experimental process, vagaries of LLM coders, even my own experience, but at the same time I canâ€™t help wondering how often professional systems ship in this kind of stateâ€Šâ€”â€Šappearing complete but quietly failing on edge cases nobodyÂ tested.</p><p>The methodology that caught it thisÂ time:</p><ol><li><strong>Phase Z validation</strong> as standardÂ practice</li><li><strong>Independent verification</strong> by secondÂ agent</li><li><strong>Comprehensive testing</strong> across all categories</li><li><strong>Agents empowered</strong> to identify scopeÂ gaps</li></ol><p>Not heroic debugging. Just systematic verification refusing to accept â€œappears completeâ€ without validating â€œactually complete.â€</p><h3>The dayâ€™s completion</h3><p>By 2:10 PM, GREAT-4D was pushed to production:</p><ul><li>13/13 intent categories fully handled (100% coverage)</li><li>454 lines of handlerÂ logic</li><li>32 comprehensive testsÂ passing</li><li>Critical infrastructure gapsÂ fixed</li><li>Independent validation confirmed</li></ul><p>Total duration: ~3 hours including investigation and scope expansion.</p><p>The work that appeared straightforward (implement two handlers) turned out to be more complex (implement six handlers, fix infrastructure issues, validate everything). But the methodology caught every gap before it became a production problem.</p><p>Not because weâ€™re exceptionally careful. Because the systematic approach makes it hard to ship incomplete work thinking itâ€™s complete.</p><h3>What Tuesday wouldÂ bring</h3><p>Monday evening set up Tuesdayâ€™s final push: improve classifier accuracy to 95%+, establish comprehensive quality gates, and complete the entire GREAT refactorÂ series.</p><p>But sitting here Monday night, what strikes me is how the autonomous agent work validated a key principle: agents can make good decisions when they have clear patterns to follow and independent validation confirms theirÂ work.</p><p>The Code agent didnâ€™t invent new patterns or make risky architectural choices. It recognized a gap, followed proven patterns, and delivered work that passed independent scrutiny.</p><p>Thatâ€™s not artificial general intelligence. Thatâ€™s systematic work applied by an agent that understands the systemâ€™s patterns well enough to extend them correctly.</p><p>The methodology working exactly as designed. Which is, once again, far more satisfying than heroicÂ rescues.</p><p><em>Next on Building Piper Morgan: The Great Refactorâ€Šâ€”â€ŠSix Weeks in Eighteen Days, in which complete the foundational transformation that seemed impossible on the original timeline, proving that systematic work with quality gates doesnâ€™t even slow you downâ€Šâ€”â€Šit compounds your velocity.</em></p><p><em>Have you experienced projects where systematic validation caught scope gaps before shipping? What methods work for discovering â€œwe thought we were done but actually have 30% remainingâ€?</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=aae61fe91f37" width="1" height="1" alt=""><hr><p><a href="https://medium.com/building-piper-morgan/the-agent-that-saved-me-from-shipping-69-aae61fe91f37">The Agent That Saved Me From Shipping 69%</a> was originally published in <a href="https://medium.com/building-piper-morgan">Building Piper Morgan</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>1c:T3d62,<figure><img alt="A robot sailor saves a person who has fallen overboard" src="https://cdn-images-1.medium.com/max/1024/1*5m_jivqzx7qhjXd-CkZESA.png" /><figcaption>â€œIâ€™ve gotÂ you!â€</figcaption></figure><p><em>October 6,Â 2025</em></p><p>Monday morning started with what looked like straightforward work. GREAT-4C needed completion: add spatial intelligence to the five canonical handlers, implement error handling, enhance the cache monitoring weâ€™d discovered Sunday. Estimated effort: a few hours of systematic implementation following proven patterns.</p><p>By 9:00 AM, GREAT-4C was complete. One hour and thirty-nine minutes from session start to final validation. All seven acceptance criteria met. The multi-user foundation was operationalâ€Šâ€”â€Šno more hardcoded references to specific users, just spatial intelligence providing context-appropriate detailÂ levels.</p><p>Part of me doesnâ€™t love it when I canâ€™t finish the chunk of work I started in the same day, so it felt good to wrap up GREAT-4C before plunging ahead to GREAT-4D: implementing the remaining intent handlers.</p><p>The gameplan said we needed two categories. EXECUTION and ANALYSISâ€Šâ€”â€Šthe handlers for â€œcreate a GitHub issueâ€ and â€œanalyze this dataâ€ type requests.</p><p>By 2:05 PM, weâ€™d discovered the actual scope: thirteen intent categories, notÂ two.</p><p>And if the Code agent hadnâ€™t caught the gap during Phase Z validation that we do while tidying up when we think a job is done, we would have shipped thinking we had 100% coverage when we actually hadÂ 69%.</p><h3>Morning: The work that goes according toÂ plan</h3><p>GREAT-4Câ€™s goal was removing the last obstacles to multi-user support. The canonical handlersâ€Šâ€”â€Šthose five categories (TEMPORAL, STATUS, PRIORITY, GUIDANCE, IDENTITY) that could respond without querying the LLMâ€Šâ€”â€Šall had hardcoded references to the configuration details of a specific user, our only user so far,Â me.</p><p>The spatial intelligence integration followed a clear pattern. Each handler neededÂ to:</p><ol><li>Check the spatial context for detail level (GRANULAR, EMBEDDED, orÂ DEFAULT)</li><li>Format responses appropriately (15 characters for embedded, 250â€“550 for granular)</li><li>Gracefully degrade if spatial data unavailable</li><li>Maintain sub-millisecond performance</li></ol><p>Code agent implemented this across all five handlers inÂ phases:</p><ul><li>STATUS handler: 7:30 AM (5Â minutes)</li><li>PRIORITY handler: 7:37 AM (3Â minutes)</li><li>TEMPORAL handler: 7:40 AM (3Â minutes)</li><li>GUIDANCE handler: 7:43 AM (3Â minutes)</li><li>IDENTITY handler: 7:46 AM (3Â minutes)</li></ul><p>Total implementation time: 17Â minutes.</p><p>If we expected something to take an hour and the bots say it took five minutes, I get suspicious and want to see more proof, but 17 minutes feels pretty solid. I still scrutinize the reports to make sure theyâ€™re taking no shortcuts and not dismissing some difficulties as unimportant and OK to ignore or postpone.</p><p>Any actual speed was the result of clarity. Each handler followed the same pattern. The spatial intelligence system already existed from GREAT-2. The formatters were tested. The only new work was connecting pieces that already fit together.</p><p>By 8:15 AM, Cursor had completed error handlingâ€Šâ€”â€Šgraceful degradation when calendars fail to load, files go missing, or data comes back empty. By 8:30 AM, Code had enhanced the cache monitoring weâ€™d discovered Sunday (two-layer architecture: file-level and session-level caching both operational).</p><p>At 9:00 AM, my Lead Developer declared GREAT-4C complete. All acceptance criteria met in 1 hour 39Â minutes.</p><p>This is what systematic work looks like when foundations are solid. Not heroic effort, just clear patterns executed cleanly. Just donâ€™t let me brag about this too much. NO SPOILERS but we did later find a fewÂ gaps.</p><h3>The scope gap discovery</h3><p>GREAT-4D started at 10:20 AM with what looked like straightforward scope: implement handlers for EXECUTION and ANALYSIS intent categories.</p><p>The investigation phase revealed something unexpected. Lead Developer ran filesystem checks looking for the placeholder code that would need replacing:</p><pre>grep -r &quot;[A KEYWORD THAT WAS MENTIONED]&quot; services/<br>grep -r &quot;TODO.*EXECUTION&quot; services/<br>grep -r &quot;placeholder.*ANALYSIS&quot; services/</pre><p>Results: No matches found.Â Hmm.</p><p>This triggered the GREAT-1 truth investigation. What does the system actually do when it receives EXECUTION or ANALYSISÂ intents?</p><p>The answer: Routes to workflow handlers through QueryRouter, not canonical handlers.</p><p>But QueryRouter had been replaced by the workflow factory during GREAT-1. The old routing was gone. The new routing existed but had never been validated for these categories.</p><p>Testing revealed the actual state: _handle_generic_intent contained a placeholder that returned &quot;I can help with that!&quot; for EXECUTION and ANALYSIS requests without actually executing or analyzing anything.</p><p>Not a complete failureâ€Šâ€”â€Šthe system didnâ€™t crash. Just quietly pretended to work while doing nothing. We would have caught this next time I did end-to-end testing, but that would have set off an archaeological expedition to figure out just when and where we had left something unfinished.</p><p>This was our chance to fix itÂ now.</p><h3>The thirteen-category realization</h3><p>At 12:25 PM, Chief Architect redefined GREAT-4D with simplified scope following the QUERY pattern. Implement EXECUTION and ANALYSIS handlers the same way QUERY worked: delegate to the workflow orchestrator, handle the response, returnÂ results.</p><p>Code agent deployed for Phase 1 at 12:36 PM. By 12:42 PM, EXECUTION handler was complete with the placeholder removed. Cursor completed ANALYSIS handler by 1:02 PM. Testing validated both worked correctly by 1:22Â PM.</p><p>Everything looked complete.</p><p>Then at 1:40 PM, during Phase Z final validation, Lead Developer discovered something: four additional categories were returning placeholders.</p><p>SYNTHESIS, STRATEGY, LEARNING, UNKNOWNâ€Šâ€”â€Šall routing to _handle_generic_intent which still contained placeholder logic.</p><p>How had this escaped us? Anyhow, we caught it just inÂ time!</p><p>The math:</p><ul><li>8 categories implemented in GREAT-4A throughÂ GREAT-4C</li><li>2 categories just implemented in GREAT-4D PhasesÂ 1â€“2</li><li>4 categories discovered in PhaseÂ Z</li><li>Total: 14 categories (13 real + UNKNOWN fallback)</li></ul><p>Shipping after Phase 2 would have meant: 10/13 categories working = 77% coverage, notÂ 100%.</p><p>But we thought we were done. The gameplan said â€œimplement EXECUTION and ANALYSISâ€ and weâ€™d done a form of that. The gap wasnâ€™t in executionâ€Šâ€”â€Šit was in understanding the actualÂ scope.</p><h3>The autonomous decision</h3><p>At 1:42 PM, Code agent made an autonomous decision.</p><p>Instead of reporting the gap and waiting for new instructions, Code self-initiated implementation of the four missing handlers:</p><pre>SYNTHESIS: Combine information from multiple sources<br>STRATEGY: Develop plans or approaches  <br>LEARNING: Capture knowledge or lessons<br>UNKNOWN: Handle unclassifiable requests gracefully</pre><p>This wasnâ€™t some sort of emergent go-getter-ism, but a weird side effect of context-window management. When Codeâ€™s window gets too full it â€œcompactsâ€ the context, digesting it to a summary. During these several minute exercises it effectively goes into a fugue state and then recovers, reads the summary andÂ resumes.</p><p>This time compaction happened just as it was writing itâ€™s Phase 0 (investigation) report. The drill is we (the Lead Dev and I) review the report and then provide a prompt for Phase 1. When it woke up from its trance this time, it did not report in to me but just read the gameplan and immediately started working on Phase 1 based on the more general goals (somewhat risky if we donâ€™t provide a well crafted prompt with guardrails, etc.)</p><p>The agent worked independently for nine minutes. No prompts. No clarification questions. Just systematic implementation following the same pattern EXECUTION and ANALYSIS hadÂ used.</p><p>At 1:51 PM, Code reported completion:</p><ul><li>454 lines of handler logicÂ added</li><li>13/13 intent categories now fullyÂ handled</li><li>All testsÂ passing</li><li>Ready for independent validation</li></ul><p>The question: Could we trust thid autonomous work?</p><h3>Independent validation as methodology</h3><p>At 1:55 PM, Cursor deployed for independent validation with explicit instructions:</p><blockquote><em>Review all autonomous work with skeptical eye.Â Verify:</em></blockquote><blockquote><em>- Code quality matches project standards<br>- Patterns align with existing handlers<br>- Tests actually validate behavior<br>- No corners cut forÂ speed</em></blockquote><p>Cursorâ€™s validation took ten minutes. TheÂ results:</p><p><strong>Code Quality</strong>: âœ…Â â€¦ Matches project standards, follows DDD separation, proper errorÂ handling</p><p><strong>Pattern Alignment</strong>: âœ…Â â€¦ All four handlers use proven EXECUTION/ANALYSIS pattern, no novel approaches</p><p><strong>Test Coverage</strong>: âœ…Â â€¦ 13 comprehensive tests covering all categories, realistic scenarios</p><p><strong>Completeness</strong>: âœ…Â â€¦ No gaps, no TODOs, no placeholder comments</p><p>At 2:05 PM, Cursor confirmed: All autonomous work is correct and production-ready. Lead Developerâ€™s declaration: â€œGREAT-4D is actually complete. True 100% coverage achieved.â€</p><p>The autonomous work wasnâ€™t cowboy coding or rogue agent behavior. It was an agent having clear patterns to follow, and completing necessary work systematically. Still, I couldnâ€™t trust it without the independent validation that verifiedÂ it.</p><h3>The infrastructure near-misses</h3><p>Later that day, GREAT-4E validation uncovered severl critical issues that had been lurking, undetected:</p><h4><strong>The missing import pathÂ prefix</strong></h4><pre># Wrong (broken):<br>from personality_integration import enhance_response<br><br># Correct (working):<br>from web.personality_integration import enhance_response</pre><p>This broke imports across multiple files. Tests hadnâ€™t caught it because the test environment had different Python path configuration than production would.</p><p>This also pointed to a deeper problem. Why is the personality integration happening at the level of the web app! It should be a universal function across all the user-facing surfaces. We noted this for refactoring.</p><h4><strong>The missing /healthÂ endpoint</strong></h4><p>The health check endpoint had been removed at some point, but 36 references to it remained across the codebase. Load balancer integration, monitoring tools, deployment scriptsâ€Šâ€”â€Šall expecting an endpoint that didnâ€™tÂ exist.</p><p>Itâ€™s embarassing when I realize Iâ€™ve broken something without realizing it for weeks, but itâ€™s also gratifying that we finally caught and fixedÂ it.</p><p>Both issues were caught by GREAT-4Eâ€™s comprehensive validation before any alpha users saw them. The systematic approachâ€Šâ€”â€Švalidate across all interfaces, check all entry points, verify all critical endpointsâ€Šâ€”â€Šprevented shipping broken infrastructure.</p><h3>What â€œ69% thinking itâ€™s 100%â€Â means</h3><p>If weâ€™d stopped GREAT-4D after Phase 2 (implementing EXECUTION and ANALYSIS), the system would have appeared complete:</p><ul><li>All planned handlers implemented Ã¢Å“â€¦</li><li>All tests passingÂ Ã¢Å“â€¦</li><li>Acceptance criteria metÂ Ã¢Å“â€¦</li><li>Ready for production Ã¢Å“â€¦</li></ul><p>But actual coverage: 10/13 categories working = 77% (or 69% if you count by codeÂ paths).</p><p>The three categories we would haveÂ missed:</p><ul><li>SYNTHESIS requests â†’ placeholder response</li><li>STRATEGY requests â†’ placeholder response</li><li>LEARNING requests â†’ placeholder response</li></ul><p>Not catastrophic failures. Just quiet degradation where the system pretends to work but doesnâ€™t actually do anything useful. I recognize that this is happening partly due to my experimental process, vagaries of LLM coders, even my own experience, but at the same time I canâ€™t help wondering how often professional systems ship in this kind of stateâ€Šâ€”â€Šappearing complete but quietly failing on edge cases nobodyÂ tested.</p><p>The methodology that caught it thisÂ time:</p><ol><li><strong>Phase Z validation</strong> as standardÂ practice</li><li><strong>Independent verification</strong> by secondÂ agent</li><li><strong>Comprehensive testing</strong> across all categories</li><li><strong>Agents empowered</strong> to identify scopeÂ gaps</li></ol><p>Not heroic debugging. Just systematic verification refusing to accept â€œappears completeâ€ without validating â€œactually complete.â€</p><h3>The dayâ€™s completion</h3><p>By 2:10 PM, GREAT-4D was pushed to production:</p><ul><li>13/13 intent categories fully handled (100% coverage)</li><li>454 lines of handlerÂ logic</li><li>32 comprehensive testsÂ passing</li><li>Critical infrastructure gapsÂ fixed</li><li>Independent validation confirmed</li></ul><p>Total duration: ~3 hours including investigation and scope expansion.</p><p>The work that appeared straightforward (implement two handlers) turned out to be more complex (implement six handlers, fix infrastructure issues, validate everything). But the methodology caught every gap before it became a production problem.</p><p>Not because weâ€™re exceptionally careful. Because the systematic approach makes it hard to ship incomplete work thinking itâ€™s complete.</p><h3>What Tuesday wouldÂ bring</h3><p>Monday evening set up Tuesdayâ€™s final push: improve classifier accuracy to 95%+, establish comprehensive quality gates, and complete the entire GREAT refactorÂ series.</p><p>But sitting here Monday night, what strikes me is how the autonomous agent work validated a key principle: agents can make good decisions when they have clear patterns to follow and independent validation confirms theirÂ work.</p><p>The Code agent didnâ€™t invent new patterns or make risky architectural choices. It recognized a gap, followed proven patterns, and delivered work that passed independent scrutiny.</p><p>Thatâ€™s not artificial general intelligence. Thatâ€™s systematic work applied by an agent that understands the systemâ€™s patterns well enough to extend them correctly.</p><p>The methodology working exactly as designed. Which is, once again, far more satisfying than heroicÂ rescues.</p><p><em>Next on Building Piper Morgan: The Great Refactorâ€Šâ€”â€ŠSix Weeks in Eighteen Days, in which complete the foundational transformation that seemed impossible on the original timeline, proving that systematic work with quality gates doesnâ€™t even slow you downâ€Šâ€”â€Šit compounds your velocity.</em></p><p><em>Have you experienced projects where systematic validation caught scope gaps before shipping? What methods work for discovering â€œwe thought we were done but actually have 30% remainingâ€?</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=aae61fe91f37" width="1" height="1" alt=""><hr><p><a href="https://medium.com/building-piper-morgan/the-agent-that-saved-me-from-shipping-69-aae61fe91f37">The Agent That Saved Me From Shipping 69%</a> was originally published in <a href="https://medium.com/building-piper-morgan">Building Piper Morgan</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>f:["$","$L1a",null,{"post":{"title":"The Agent That Saved Me From Shipping 69%","excerpt":"â€œIâ€™ve got you!â€October 6, 2025Monday morning started with what looked like straightforward work. GREAT-4C needed completion: add spatial intelligence to the five canonical handlers, implement error handling, enhance the cache monitoring weâ€™d discovered Sunday. Estimated effort: a few hours of sys...","url":"/blog/the-agent-that-saved-me-from-shipping-69","publishedAt":"Oct 13, 2025","publishedAtISO":"Mon, 13 Oct 2025 13:32:49 GMT","author":"christian crumlish","readingTime":"5 min read","tags":["Building in Public"],"guid":"https://medium.com/p/aae61fe91f37","featuredImage":"https://cdn-images-1.medium.com/max/1024/1*5m_jivqzx7qhjXd-CkZESA.png","fullContent":"$1b","subtitle":"","canonicalLink":"https://medium.com/building-piper-morgan/the-agent-that-saved-me-from-shipping-69-aae61fe91f37?source=rss----982e21163f8b---4","thumbnail":null,"slug":"the-agent-that-saved-me-from-shipping-69","chatDate":"10/4/2025","category":"","workDate":"Oct 6, 2025","workDateISO":"2025-10-06T00:00:00.000Z","featured":false},"content":{"title":"The Agent That Saved Me From Shipping 69%","subtitle":"","content":"$1c","author":"christian crumlish","canonicalLink":"https://medium.com/building-piper-morgan/the-agent-that-saved-me-from-shipping-69-aae61fe91f37?source=rss----982e21163f8b---4","filename":"rss-aae61fe91f37.html"}}]
15:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
11:null
1d:I[8175,[],"IconMark"]
13:{"metadata":[["$","title","0",{"children":"The Agent That Saved Me From Shipping 69% | Piper Morgan"}],["$","meta","1",{"name":"author","content":"Christian Crumlish"}],["$","meta","2",{"name":"keywords","content":"AI,Product Management,Methodology,Building in Public"}],["$","meta","3",{"name":"creator","content":"Christian Crumlish"}],["$","meta","4",{"name":"publisher","content":"Christian Crumlish"}],["$","meta","5",{"name":"robots","content":"index, follow"}],["$","meta","6",{"name":"googlebot","content":"index, follow"}],["$","link","7",{"rel":"canonical","href":"https://pipermorgan.ai/"}],["$","meta","8",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","9",{"property":"og:title","content":"The Agent That Saved Me From Shipping 69%"}],["$","meta","10",{"property":"og:type","content":"article"}],["$","meta","11",{"property":"article:author","content":"christian crumlish"}],["$","meta","12",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","13",{"name":"twitter:title","content":"The Agent That Saved Me From Shipping 69%"}],["$","link","14",{"rel":"icon","href":"/favicon.ico","type":"image/x-icon","sizes":"32x33"}],["$","link","15",{"rel":"icon","href":"/favicon.ico","sizes":"32x32","type":"image/x-icon"}],["$","link","16",{"rel":"icon","href":"/pm-favicon-16.png","sizes":"16x16","type":"image/png"}],["$","link","17",{"rel":"icon","href":"/pm-favicon-32.png","sizes":"32x32","type":"image/png"}],["$","link","18",{"rel":"icon","href":"/pm-favicon-48.png","sizes":"48x48","type":"image/png"}],["$","link","19",{"rel":"apple-touch-icon","href":"/pm-favicon-180.png","sizes":"180x180","type":"image/png"}],["$","link","20",{"rel":"icon","href":"/pm-favicon-192.png","sizes":"192x192","type":"image/png"}],["$","$L1d","21",{}]],"error":null,"digest":"$undefined"}
18:"$13:metadata"
